{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc664edf",
   "metadata": {},
   "source": [
    "ZZ Feature Map Algorithm 1 test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de16c4",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d659b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit import Aer, transpile\n",
    "\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.circuit.library import PauliFeatureMap\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.circuit.library import StatePreparation\n",
    "\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "import qiskit_machine_learning.kernels\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from qiskit.providers.aer import AerError\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "algorithm_globals.random_seed = 1\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "from qiskit.algorithms.linear_solvers.numpy_linear_solver import NumPyLinearSolver\n",
    "from qiskit.algorithms.linear_solvers.hhl import HHL\n",
    "from qiskit.quantum_info import DensityMatrix\n",
    "from functools import reduce\n",
    "from sympy import Matrix\n",
    "from sympy import sqrt as special_sqrt\n",
    "from qiskit import *\n",
    "from qiskit.extensions import HamiltonianGate\n",
    "from qiskit.quantum_info import Operator\n",
    "\n",
    "dataset_list = []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4a5f750",
   "metadata": {},
   "source": [
    "Code used to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4925e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(13)\n",
    "seed = 0\n",
    "x, y = make_blobs(n_samples=3, centers=1, cluster_std=.02, center_box=(0.5, 0.5), random_state=seed)\n",
    "\n",
    "out1x, out1y = make_blobs(n_samples=1, centers=1, cluster_std=.01, center_box=(0.6,0.5), random_state=seed)\n",
    "# out2x, out2y = make_blobs(n_samples=11, centers=1, cluster_std=.1, center_box=(3.2, 0.01), random_state=seed)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# prepare data for One-Class model\n",
    "y[y == 0] = 1\n",
    "out1y[out1y==0] = -1 \n",
    "# out2y[out2y==0] = -1 \n",
    "\n",
    "x = np.append(x, out1x, axis = 0)\n",
    "y = np.append(y, out1y, axis = 0)\n",
    "\n",
    "# x = np.append(x, out2x, axis = 0)\n",
    "# y = np.append(y, out2y, axis = 0)\n",
    "\n",
    "# Plot to see data\n",
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.scatter(out1x[:,0], out1x[:,1])\n",
    "# plt.scatter(out2x[:,0], out2x[:,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Add data to dataset_list\n",
    "dataset_list.append([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second dataset: ZZFeatureMap ad_hoc data\n",
    "# adhoc_dimension = 2\n",
    "# train_features, train_labels, test_features, test_labels, adhoc_total = ad_hoc_data(\n",
    "#     training_size=80,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.3,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=True,\n",
    "# )\n",
    "# train_features_out, train_labels_out, _, _ = ad_hoc_data(\n",
    "#     training_size=10,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.6,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "# # adhoc_total[adhoc_total == 0] = 1\n",
    "\n",
    "# # print(train_features)\n",
    "# # print(train_labels)\n",
    "\n",
    "# # Change labels for One-Class\n",
    "# train_labels_out[train_labels_out != -1] = -1\n",
    "\n",
    "# # Now we have to add the outliers\n",
    "# train_features = np.append(train_features, train_features_out, axis = 0)\n",
    "# train_labels = np.append(train_labels, train_labels_out, axis = 0)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.ylim(0, 2 * np.pi)\n",
    "# plt.xlim(0, 2 * np.pi)\n",
    "# plt.imshow(\n",
    "#     np.asmatrix(adhoc_total).T,\n",
    "#     interpolation=\"nearest\",\n",
    "#     origin=\"lower\",\n",
    "#     cmap=\"RdBu\",\n",
    "#     extent=[0, 2 * np.pi, 0, 2 * np.pi],\n",
    "# )\n",
    "\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 0), 0],\n",
    "#     train_features[np.where(train_labels[:] == 0), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"b\",\n",
    "#     label=\"Training Label A\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 1), 0],\n",
    "#     train_features[np.where(train_labels[:] == 1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "#     label=\"Training Label B\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == -1), 0],\n",
    "#     train_features[np.where(train_labels[:] == -1), 1],\n",
    "#     marker=\"s\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"Outliers\",\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0.0)\n",
    "# plt.title(\"Ad hoc dataset for classification\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # We don't need the second label for one-class SVMs, so change 0 label to 1\n",
    "# train_labels[train_labels == 0] = 1\n",
    "\n",
    "\n",
    "# # add data to dataset_list\n",
    "# dataset_list.append([train_features,train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e8ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Third dataset, create blob and add zz feature map data to it\n",
    "# random.seed(13)\n",
    "# seed = 23\n",
    "# x, y = make_blobs(n_samples=190, centers=1, cluster_std=3, center_box=(3, 3), random_state=seed)\n",
    "# train_features_out2, train_labels_out2, _, _ = ad_hoc_data(\n",
    "#     training_size=10,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.5,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "\n",
    "# # prepare data for One-Class model\n",
    "# y[y == 0] = 1\n",
    "# train_labels_out2[train_labels_out2 != -1] = -1 \n",
    "\n",
    "# # add outliers to data\n",
    "# x = np.append(x, train_features_out2, axis = 0)\n",
    "# y = np.append(y, train_labels_out2, axis = 0)\n",
    "\n",
    "# # Plot to see data\n",
    "# plt.scatter(x[:,0], x[:,1])\n",
    "# plt.scatter(\n",
    "#     train_features_out2[np.where(train_labels_out2[:] == -1), 0],\n",
    "#     train_features_out2[np.where(train_labels_out2[:] == -1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "#     label=\"Training Label B\",\n",
    "# )\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Add data to dataset_list\n",
    "# dataset_list.append([x,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f41d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adhoc_dimension = 2\n",
    "# train_features, train_labels, _,_ = ad_hoc_data(\n",
    "#     training_size=80,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.6,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "# x, y = make_blobs(n_samples=20, centers=3, cluster_std=2, center_box=(3, 3), random_state=111)\n",
    "\n",
    "# # prepare data for One-Class model\n",
    "# train_labels[train_labels == 0] = 1\n",
    "# y[y != -1] = -1 \n",
    "\n",
    "# # add outliers to data\n",
    "# train_features = np.append(train_features, x, axis = 0)\n",
    "# train_labels = np.append(train_labels, y, axis = 0)\n",
    "\n",
    "# # Plot to see data\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 1), 0],\n",
    "#     train_features[np.where(train_labels[:] == 1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"b\",\n",
    "#     label=\"Training Label A\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     x[np.where(y[:] == -1), 0],\n",
    "#     x[np.where(y[:] == -1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "# )\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Add data to dataset_list\n",
    "# dataset_list.append([train_features,train_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094a8ae",
   "metadata": {},
   "source": [
    "Save/Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d2a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as fileload:\n",
    "        file = pickle.load(fileload)\n",
    "    return file\n",
    "# save_object(dataset_list, \"datasets_small\")\n",
    "dataset_list = load_object(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6703d",
   "metadata": {},
   "source": [
    "Custom Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8aaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_map_func(x):\n",
    "    mapped = x[0] if len(x) == 1 else reduce(lambda m, n: m * n, x)\n",
    "    return mapped\n",
    "def feature_map_superfidel(x):\n",
    "    # as described in \n",
    "    # https://doi.org/10.1103/PhysRevA.97.042315\n",
    "    \n",
    "    # Qiskit currently doesn't natively support a square root function in a parameter expression\n",
    "    # So use sympy base to get the same effect\n",
    "    mapped = x[0] if len(x) == 1 else reduce(lambda m, n: m * n, \n",
    "                                             np.divide(x,(1-np.square(np.column_stack(x)).trace())._call(special_sqrt)))\n",
    "    if len(x) != 1:\n",
    "        print(1-np.square(np.column_stack(x)).trace())\n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e32a7",
   "metadata": {},
   "source": [
    "Quantum Function for OneClass (Algorithm 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f58ba946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First algorithm, returns trained model\n",
    "def Algorithm1(X, y, reps=2, shots=1, outliers_fraction=20/210,\n",
    "               entanglement=\"linear\", num_features = 2, seed = 0, \n",
    "               supervised=False, feature_map_no = 1, data_map_no = 1, paulis = [\"Z\", \"ZZ\"]) :\n",
    "    if feature_map_no == 1:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        if data_map_no == 1:\n",
    "             feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement)\n",
    "        elif data_map_no == 2:\n",
    "            feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement, \n",
    "                                       data_map_func = custom_data_map_func)\n",
    "        elif data_map_no == 3:\n",
    "            feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement, \n",
    "                                       data_map_func = feature_map_superfidel)\n",
    "    elif feature_map_no == 2:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        feature_map = ZFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "    elif feature_map_no == 3:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        feature_map = PauliFeatureMap(feature_dimension = num_features, reps = reps, paulis=paulis)\n",
    "    # Calculates probabilities of bit results from quantum circuits\n",
    "    sampler = Sampler()\n",
    "    # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    # Translates data with base state fidelity distance metric\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    # Kernel needs to be evaluated before going into the One-Class SVM\n",
    "    svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "    if supervised: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=seed)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        # TODO save to Matrix\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "#         print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "#         print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "    else: \n",
    "        svm.fit(X)\n",
    "        y_pred = svm.predict(X)\n",
    "        #TODO save to matrix\n",
    "#         print(classification_report(y, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0a968",
   "metadata": {},
   "source": [
    "Showcase of Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bba916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dataset: 1\n",
      "\n",
      "For pauli matrix: ['X', 'XX']\n",
      "[LibSVM]Accuracy: 0.9095238095238095\n",
      "Precision 1: 0.9476439790575916\n",
      "Precision -1: 0.5263157894736842\n",
      "Recall 1: 0.7263157894736842\n",
      "F1 1: 0.7314758732081567\n",
      "F1 1: 0.9501312335958004\n",
      "F1 -1: 0.5128205128205129\n",
      "For pauli matrix: ['Y', 'XX']\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "dataset_count = 0\n",
    "outliers_fraction=20/210\n",
    "entanglement_list = [\"full\", 'linear']\n",
    "data_map_list = []\n",
    "# for X, y in dataset_list:\n",
    "#     dataset_count = dataset_count + 1\n",
    "#     print()\n",
    "#     print(\"For dataset: {}\".format(dataset_count))\n",
    "#     print()\n",
    "# #     if dataset_count == 2:\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2)\n",
    "# #     if dataset_count == 3:\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2, data_map_no=2)\n",
    "# #     if dataset_count == 4:\n",
    "#         # THIS One is slightly better\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2, data_map_no=3)\n",
    "#     Algorithm1(X, y, reps=4)\n",
    "#     print()\n",
    "#     print(\"For dataset: {}\".format(dataset_count))\n",
    "#     print()\n",
    "#     print(\"Experiment with number of repetitions 1,2,3\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For reps: {}\".format(i))\n",
    "#         Algorithm1(X, y, reps=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different Feature maps\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For feature_map: {}\".format(i))\n",
    "#         Algorithm1(X, y, feature_map_no=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different entanglements\")\n",
    "#     for i in entanglement_list:\n",
    "#         print(\"For entanglement: {}\".format(i))\n",
    "#         Algorithm1(X, y, entanglement=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different data_maps\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For data_map: {}\".format(i))\n",
    "#         Algorithm1(X, y, data_map_no=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different shots\")\n",
    "#     for i in range(1,5,2):\n",
    "#         print(\"For shots: {}\".format(i))\n",
    "#         Algorithm1(X, y, shots=i)\n",
    "\n",
    "# fit data to OneClassSVM\n",
    "# svm.fit(precomp_kernel_real)\n",
    "Pmatrices = [\"X\", \"Y\", \"Z\"]\n",
    "paulis_list = []\n",
    "def combp(pm, prefix, n, k, fullermatrix):\n",
    "    if (k == 0) :\n",
    "        fullermatrix.append(prefix)\n",
    "        return fullermatrix\n",
    "    for i in range(n):\n",
    "        newPrefix = prefix + pm[i]\n",
    "        combp(pm, newPrefix, n, k - 1, fullermatrix)\n",
    "    return fullermatrix\n",
    "paulis_list = combp(Pmatrices,\"\",len(Pmatrices),2,paulis_list)\n",
    "secondpaulis_list = []\n",
    "for e in paulis_list:\n",
    "    for i in Pmatrices:\n",
    "        secondpaulis_list.append([i,e])\n",
    "secondpaulis_list.append([\"I\", \"II\"])\n",
    "\n",
    "\n",
    "\n",
    "# Experiment with Pauli Matrices here\n",
    "for X, y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print()\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    print()\n",
    "    for m in secondpaulis_list:\n",
    "        print(\"For pauli matrix: {}\".format(m))\n",
    "        Algorithm1(X, y, feature_map_no=3, paulis=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22168876",
   "metadata": {},
   "source": [
    "Comparison to other One-Class SVM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e8057e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dataset: 1\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8904761904761904\n",
      "Precision 1: 0.93717277486911\n",
      "Precision -1: 0.42105263157894735\n",
      "Recall 1: 0.6710526315789473\n",
      "F1 1: 0.6749444780940843\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.9714285714285714\n",
      "Precision 1: 0.9842105263157894\n",
      "Precision -1: 0.85\n",
      "Recall 1: 0.9171052631578946\n",
      "F1 1: 0.9171052631578946\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.9714285714285714\n",
      "Precision 1: 0.9842105263157894\n",
      "Precision -1: 0.85\n",
      "Recall 1: 0.9171052631578946\n",
      "F1 1: 0.9171052631578946\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.09523809523809523\n",
      "Precision 1: 0.0\n",
      "Precision -1: 0.09523809523809523\n",
      "Recall 1: 0.5\n",
      "F1 1: 0.08695652173913042\n",
      "\n",
      "For dataset: 2\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "\n",
      "For dataset: 3\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.7904761904761904\n",
      "Precision 1: 0.8924731182795699\n",
      "Precision -1: 0.0\n",
      "Recall 1: 0.4368421052631579\n",
      "F1 1: 0.44148936170212766\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.6047619047619047\n",
      "Precision 1: 0.9212598425196851\n",
      "Precision -1: 0.12048192771084337\n",
      "Recall 1: 0.5578947368421052\n",
      "F1 1: 0.466172552142354\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.6619047619047619\n",
      "Precision 1: 0.9103448275862069\n",
      "Precision -1: 0.1076923076923077\n",
      "Recall 1: 0.5223684210526316\n",
      "F1 1: 0.4763827919227393\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8095238095238095\n",
      "Precision 1: 0.8947368421052632\n",
      "Precision -1: 0.0\n",
      "Recall 1: 0.4473684210526316\n",
      "F1 1: 0.4473684210526316\n",
      "\n",
      "For dataset: 4\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8555555555555555\n",
      "Precision 1: 0.9085365853658537\n",
      "Precision -1: 0.3125\n",
      "Recall 1: 0.590625\n",
      "F1 1: 0.5987654320987654\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.8333333333333334\n",
      "Precision 1: 0.8963414634146342\n",
      "Precision -1: 0.1875\n",
      "Recall 1: 0.5343749999999999\n",
      "F1 1: 0.537037037037037\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "other_kernel_list = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "outliers_fraction=20/210\n",
    "dataset_count = 0\n",
    "supervised = False\n",
    "for X,y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print()\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    for kernel in other_kernel_list:\n",
    "        svm_classical = OneClassSVM(kernel = kernel, verbose=True,  nu=outliers_fraction)\n",
    "        if supervised:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "            svm_classical.fit(X_train, y_train)\n",
    "            y_pred = svm_classical.predict(X_test)\n",
    "            # TODO save to Matrix\n",
    "            print(\"{}: \".format(kernel))\n",
    "#             print(classification_report(y_test, y_pred))\n",
    "            print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "            \n",
    "            print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "            print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "            print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='macro')))\n",
    "            print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "            \n",
    "#             print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "#             print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "#             print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "#             print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        else:\n",
    "            svm_classical.fit(X)\n",
    "            y_pred = svm_classical.predict(X)\n",
    "            # TODO save to Matrix\n",
    "\n",
    "            print(\"{}: \".format(kernel))\n",
    "#             print(classification_report(y, y_pred))\n",
    "            print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "            \n",
    "            print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "            print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "            print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "            print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "#             print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#             print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "#             print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "#             print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480e331",
   "metadata": {},
   "source": [
    "Algorithm attempt for Nana Liu paper for Quantum SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e969bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def K(x,z, p_constant=1.0):\n",
    "    return (np.dot(x.T,z)+p_constant)**2\n",
    "\n",
    "def Algorithm2(X, y, reps=1, shots=1, outliers_fraction=1/4,entanglement=\"linear\", num_features = 2, seed = 0, supervised=False):\n",
    "    # Qiskit code for RawFeatureVector has bug, currently not in use\n",
    "    # TODO We should use RawFeatureVector to stay true to the paper, but Qiskit currently has problem with this method\n",
    "#     feature_map = RawFeatureVector(feature_dimension = num_features)\n",
    "#     print(feature_map.parameters)\n",
    "#     par0 = feature_map.parameters[0]\n",
    "#     par1 = feature_map.parameters[1]\n",
    "#     print(par0)\n",
    "#     print(par1)\n",
    "#     state = np.array([1, 1]) / np.sqrt(2)\n",
    "#     feature_map = feature_map.assign_parameters(state)\n",
    "#     theta_range = np.linspace(0, 2 * np.pi, 128)\n",
    "#     print(feature_map.parameters)\n",
    "#     feature_map = feature_map.bind_parameters({par0: 1/np.sqrt(2), par1: 1/np.sqrt(2)})\n",
    "#     feature_map = ZZFeatureMap(feature_dimension = num_features, reps = reps, entanglement=entanglement)\n",
    "#     feature_map = ZFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "#     feature_map = PauliFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "\n",
    "#     # Calculates probabilities of bit results from quantum circuits\n",
    "#     sampler = Sampler()\n",
    "#     # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "#     fidelity = ComputeUncompute(sampler=sampler)\n",
    "#     # Translates data with base state fidelity distance metric\n",
    "#     kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "#     # Kernel needs to be evaluated before going into the One-Class SVM\n",
    "\n",
    "#     # Algorithm 2 starts here \n",
    "#     svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "# #     classical_solution = NumPyLinearSolver().solve(X, y / np.linalg.norm(y))\n",
    "\n",
    "    # Trick to make matrix hermitian\n",
    "#     X = np.matrix(X)\n",
    "#     Xh = X.getH()\n",
    "#     zeroes1 = np.zeros((X.shape[0], X.shape[0]))\n",
    "#     zeroes2 = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "#     X = np.bmat([[zeroes1, X], [Xh, zeroes2]])\n",
    "#     y = np.append(y, [1,1])\n",
    "#     X = DensityMatrix(X)\n",
    "#     np.real(X)\n",
    "#     print(X)\n",
    "#     hhl = HHL()\n",
    "#     hhl.construct_circuit(X,y)\n",
    "#     inversed_matrix = hhl.solve(X,y)\n",
    "#     X = X[:128]\n",
    "#     y = y[:128]\n",
    "    # Calculate Kernel Matrix\n",
    "    K = np.dot(X, np.transpose(X))\n",
    "    \n",
    "    # Change Kernel Matrix to density matrix gram\n",
    "    K_ = np.divide(K, K.trace())\n",
    "    \n",
    "    # density matrix exponentiation technique\n",
    "    # First make matrix hermitian\n",
    "    K_ = np.matrix(K_)\n",
    "    K_h = K_.getH()\n",
    "    zeroes1 = np.zeros((K_.shape[0], K_.shape[0]))\n",
    "    zeroes2 = np.zeros((K_.shape[1], K_.shape[1]))\n",
    "    \n",
    "    hermitian_K = np.bmat([[zeroes1, K_], [K_h, zeroes2]])\n",
    "    \n",
    "   \n",
    "#     y = np.append(y, [1,1])\n",
    "    \n",
    "    \n",
    "#     K_dense = DensityMatrix(K_)\n",
    "#     K_q = Operator(K_)\n",
    "#     print(K_q)\n",
    "#     K_q = K_q.to_instruction()\n",
    "#     h = HamiltonianGate(hermitian_K, 1)\n",
    "#     print(len(K_))\n",
    "#     print(len(X))\n",
    "    \n",
    "    zeroesy = np.zeros(len(hermitian_K)-len(y))\n",
    "    new_y = np.append(y,zeroesy)\n",
    "    # invert Kernel Matrix\n",
    "    sim_mps = Aer.get_backend('aer_simulator_matrix_product_state')\n",
    "    classical_solution = NumPyLinearSolver().solve(hermitian_K, new_y / np.linalg.norm(new_y))\n",
    "    print(classical_solution)\n",
    "    return\n",
    "    hhl = HHL(epsilon=1, quantum_instance=sim_mps)\n",
    "    circuit_hhl = hhl.construct_circuit(hermitian_K,new_y, neg_vals=False)\n",
    "#     hhl0 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=0)\n",
    "#     hhl1 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=1)\n",
    "#     hhl2 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=2)\n",
    "#     hhl3 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=3)\n",
    "    print(circuit_hhl.decompose())\n",
    "    print(hhl0.decompose())\n",
    "    print(hhl1.decompose())\n",
    "    print(hhl2.decompose())\n",
    "    print(hhl3.decompose())\n",
    "\n",
    "#     inversed_matrix = hhl.solve(hermitian_K,new_y)\n",
    "    print(inversed_matrix)\n",
    "    print(inversed_matrix.observable)\n",
    "    return\n",
    "    # Test with custom feature map\n",
    "    feature_map = PauliFeatureMap(feature_dimension=2, reps=reps, data_map_func=feature_map_superfidel)\n",
    "    # Calculates probabilities of bit results from quantum circuits\n",
    "    sampler = Sampler()\n",
    "    # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    # Translates data with base state fidelity distance metric\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "\n",
    "    if supervised: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=seed)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        # TODO save to Matrix\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "    else: \n",
    "        svm.fit(X)\n",
    "        y_pred = svm.predict(X)\n",
    "        #TODO save to matrix\n",
    "#         print(classification_report(y, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "        print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e4ed2",
   "metadata": {},
   "source": [
    "Second algorithm attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d237a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataset: 1\n",
      "For reps: 2\n",
      "{   'circuit_results': None,\n",
      "    'euclidean_norm': 5.208533804241974e+16,\n",
      "    'observable': None,\n",
      "    'state': array([ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "        1.64626730e+16, -2.50993237e+15,  2.85064745e+16, -4.02857790e+16])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\AppData\\Local\\Temp/ipykernel_8420/1911906896.py:81: DeprecationWarning: The NumPyLinearSolver class is deprecated as of Qiskit Terra 0.22.0 and will be removed no sooner than 3 months after the release date. \n",
      "  classical_solution = NumPyLinearSolver().solve(hermitian_K, new_y / np.linalg.norm(new_y))\n"
     ]
    }
   ],
   "source": [
    "dataset_count = 0\n",
    "outliers_fraction=1/4\n",
    "# MAKE SMALL DATASET\n",
    "for X, y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    for i in range(2,3):\n",
    "        print(\"For reps: {}\".format(i))\n",
    "        Algorithm2(X, y, i, 1, outliers_fraction=outliers_fraction)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ed9a9",
   "metadata": {},
   "source": [
    "Quantum Auto Encoder Implementation in Qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "437d0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "from itertools import combinations\n",
    "from qibo import hamiltonians\n",
    "from qiskit.opflow import Z, I, StateFn, CircuitStateFn, SummedOp\n",
    "from qiskit.opflow import X as X_gate\n",
    "from qiskit.opflow.gradients import Gradient, NaturalGradient, QFI, Hessian\n",
    "from qiskit.circuit import QuantumCircuit, QuantumRegister, Parameter, ParameterVector, ParameterExpression\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "\n",
    "def Quantum_Autoencoder_circuit(parameters, num_qubits, num_trash_qubits, layers, num_parameters):\n",
    "    circuit = QuantumCircuit(num_qubits)\n",
    "    paramidx = 0\n",
    "    if (num_trash_qubits <= num_qubits/2):\n",
    "        for l in range(layers):\n",
    "            for idx in range(num_trash_qubits):\n",
    "                for q in range(num_qubits):\n",
    "                    #phase rotation\n",
    "                    temp_parameter = Parameter('{}'.format(paramidx))\n",
    "                    circuit.ry(temp_parameter,q)\n",
    "                    circuit.assign_parameters({temp_parameter: parameters[q+idx*num_qubits+l*num_trash_qubits*num_qubits]})\n",
    "                    paramidx += 1\n",
    "                # CZ between trash qubits\n",
    "                for i,j in combinations(range(num_qubits-num_trash_qubits,num_qubits),2):\n",
    "                    circuit.cz(i,j)\n",
    "                # CZ between trash and non-trash qubits\n",
    "                for i in range(num_trash_qubits):\n",
    "                    for j in range(i,num_qubits-num_trash_qubits,num_trash_qubits):\n",
    "                        circuit.cz(num_qubits-num_trash_qubits+((idx+i)%num_trash_qubits),j)\n",
    "    else :\n",
    "        for l in range(layers):\n",
    "            for idx in range(num_qubits-num_trash_qubits):\n",
    "                for q in range(num_qubits):\n",
    "                    #phase rotation\n",
    "                    temp_parameter = Parameter('{}'.format(paramidx))\n",
    "                    circuit.ry(temp_parameter,q)\n",
    "#                     circuit.ry(parameters[q+idx*num_qubits+l*(num_qubits-num_trash_qubits)*num_qubits],q)\n",
    "                    circuit.assign_parameters({temp_parameter: parameters[q+idx*num_qubits+l*(num_qubits-num_trash_qubits)*num_qubits]})\n",
    "                    paramidx += 1\n",
    "                # CZ between trash qubits\n",
    "                for i,j in combinations(range(num_qubits-num_trash_qubits,num_qubits),2):\n",
    "                    circuit.cz(i,j)\n",
    "                for i in range(num_qubits-num_trash_qubits):\n",
    "                    for j in range(num_qubits-num_trash_qubits+i,num_qubits,num_qubits-num_trash_qubits):\n",
    "                        circuit.cz((idx+i)%(num_qubits-num_trash_qubits),j)\n",
    "    for q in range(num_trash_qubits):\n",
    "        temp_parameter = Parameter('{}'.format(paramidx))\n",
    "        circuit.ry(temp_parameter,q)\n",
    "#         circuit.ry(parameters[num_parameters-num_trash_qubits+q], num_qubits-num_trash_qubits+q)\n",
    "        circuit.assign_parameters({temp_parameter: parameters[num_parameters-num_trash_qubits+q]})\n",
    "        paramidx += 1\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "#TODO\n",
    "def cost_hamiltonian(num_qubits, num_trash_qubits, outliers_fraction = 20/210):\n",
    "    \n",
    "    num_trash_qubits = num_trash_qubits \n",
    "#     print(num_trash_qubits)\n",
    "#     print(hamiltonians.Z(num_trash_qubits))\n",
    "#     print(hamiltonians.Z(num_trash_qubits).matrix)\n",
    "    print(hamiltonians.Z(num_trash_qubits).matrix)\n",
    "    print(type(hamiltonians.Z(num_trash_qubits).matrix))\n",
    "\n",
    "    m0 = hamiltonians.Z(num_trash_qubits).matrix.numpy()\n",
    "    m1 = np.eye(2 ** (num_qubits - num_trash_qubits), dtype=m0.dtype)\n",
    "    ham = hamiltonians.Hamiltonian(num_qubits, np.kron(m1, m0))\n",
    "\n",
    "    return 0.5 * (ham + num_trash_qubits)\n",
    "\n",
    "def data_encoding(X, encoding):\n",
    "    encoded_X = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(encoding)\n",
    "    if encoding == \"Amplitude\":\n",
    "        num_qubits = 2\n",
    "        for i in range(len(X)):\n",
    "            encoded_X.append(np.array(X[i])/np.linalg.norm(np.array(X[i])))\n",
    "    elif encoding == \"FRQI\":\n",
    "        num_qubits = 2\n",
    "        for i in range(len(X)):\n",
    "            vector = np.concatenate((np.cos(np.pi/2*np.array(X[i])),np.sin(np.pi/2*np.array(X[i]))))/8.0\n",
    "            encoded_X.append(vector/np.linalg.norm(np.array(vector)))  \n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Not a valid encoding\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return encoded_X, num_qubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af78d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "class VQOCC(): \n",
    "    def __init__(self, num_qubits, num_trash_qubits, layers):\n",
    "\n",
    "        assert num_trash_qubits < num_qubits\n",
    "\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_trash_qubits = num_trash_qubits\n",
    "        self.layers = layers\n",
    "\n",
    "        if (num_trash_qubits <= num_qubits/2):\n",
    "            num_parameters = num_trash_qubits * (num_qubits * layers + 1)\n",
    "        else:\n",
    "            num_parameters = (num_qubits-num_trash_qubits)*num_qubits*layers + num_trash_qubits\n",
    "\n",
    "        self.num_parameters = num_parameters\n",
    "        self.parameters = np.random.uniform(low=0.0, high=1.0, size=(num_parameters,))\n",
    "        self.circuit = Quantum_Autoencoder_circuit(self.parameters, num_qubits, num_trash_qubits, layers, num_parameters)\n",
    "     \n",
    "    def function(self, parameters):\n",
    "        circuit_copy = self.circuit.copy()\n",
    "\n",
    "        circuit_copy.assign_parameters(parameters, inplace=True)\n",
    "\n",
    "    #             print(parameters)\n",
    "        batch_index = np.random.randint(0, len(self.X), (self.batch_size,))\n",
    "        vector_batch = [self.X[i] for i in batch_index]\n",
    "        temp_loss = 0\n",
    "        for i in range(self.batch_size):\n",
    "    #                 circuit_copy = circuit.copy()\n",
    "    #             for i in range(len(X)-1):\n",
    "            start_qc = QuantumCircuit(2)\n",
    "            start_qc.initialize(self.X[i], start_qc.qubits[0])\n",
    "            start_qc.initialize(self.X[i], start_qc.qubits[1])\n",
    "#             start_qc.initialize(self.X[i])\n",
    "    \n",
    "            qc = start_qc + circuit_copy\n",
    "            qc.save_statevector('test1')\n",
    "            qc.measure_all()\n",
    "            qc.save_statevector('test2')\n",
    "\n",
    "            sim = Aer.get_backend('aer_simulator')\n",
    "            qobj = assemble(qc)\n",
    "            job = sim.run(qobj,shots=100)\n",
    "            result = job.result()\n",
    "            data = result.data()\n",
    "            resulting_state = data['test2'].data\n",
    "            temp_loss += self.ham.expectation(resulting_state)/(self.num_trash_qubits*self.batch_size)\n",
    "        return temp_loss\n",
    "    def train(self,X,lr=0.1,n_epochs=150,batch_size=10,verbose_loss=False):\n",
    "\n",
    "\n",
    "\n",
    "        parameters = self.parameters\n",
    "        best_parameters = self.parameters\n",
    "        loss_history = []\n",
    "        num_trash_qubits = self.num_trash_qubits\n",
    "        self.batch_size = batch_size\n",
    "        circuit = self.circuit.copy()\n",
    "        self.X = X\n",
    "        self.ham = cost_hamiltonian(self.num_qubits,num_trash_qubits)\n",
    "#         print(type(ham))\n",
    "        loss = 1\n",
    "    # ATTEMPTED GRADIENT DESCENT, WASN'T ABLE TO WORK DUE TO GRADIENT CALCULATION OF QUANTUM CIRCUIT IN QISKIT DOESNT SEEM TO BE POSSIBLE\n",
    "    \n",
    "#         for e in range(n_epochs):\n",
    "#             # Training Quantum circuit with loss functions evaluated from Hamiltonian\n",
    "#             # using automatic differentiation\n",
    "# #             print(len(parameters))\n",
    "#             circuit_copy = circuit.copy()\n",
    "    \n",
    "# #             circuit_copy.assign_parameters(parameter_tensor[0].detach().numpy(), inplace=True)\n",
    "#             circuit_copy.assign_parameters(parameters, inplace=True)\n",
    "\n",
    "# #             print(parameters)\n",
    "#             batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "#             vector_batch = [X[i] for i in batch_index]\n",
    "#             temp_loss = 0\n",
    "#             for i in range(batch_size):\n",
    "# #                 circuit_copy = circuit.copy()\n",
    "# #             for i in range(len(X)-1):\n",
    "#                 start_qc = QuantumCircuit(2)\n",
    "#                 start_qc.initialize(encoded_X[i], start_qc.qubits[0])\n",
    "#                 start_qc.initialize(encoded_X[i], start_qc.qubits[1])\n",
    "#                 qc = start_qc + circuit_copy\n",
    "#                 qc.save_statevector('test1')\n",
    "#                 qc.measure_all()\n",
    "#                 qc.save_statevector('test2')\n",
    "\n",
    "#                 sim = Aer.get_backend('aer_simulator')\n",
    "#                 qobj = assemble(qc)\n",
    "#                 job = sim.run(qobj,shots=1024)\n",
    "#                 result = job.result()\n",
    "#                 data = result.data()\n",
    "#                 resulting_state = data['test1'].data\n",
    "#                 temp_loss += self.ham.expectation(resulting_state)/(num_trash_qubits*batch_size)\n",
    "            \n",
    "# #             optimizer.zero_grad()\n",
    "# #             loss = torch.tensor(temp_loss.numpy(), requires_grad=True)\n",
    "# #             loss.backward()\n",
    "# #             print(parameter_tensor[0].grad)\n",
    "\n",
    "#             if temp_loss < loss:\n",
    "#                 loss = temp_loss\n",
    "#                 best_parameters = parameters\n",
    "#             else:\n",
    "#                 parameters = np.random.uniform(low=0.0, high=1.0, size=(len(parameters),))\n",
    "# #             loss = temp_loss\n",
    "#             print(loss)\n",
    "#             #TODO Calculate loss/parameter gradients\n",
    "            \n",
    "#             #TODO Apply gradients to parameters, and update them\n",
    "# #             print(optimizer)\n",
    "            \n",
    "#             loss_history.append(loss)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        varbound1 = [0.0,1.0]\n",
    "        vartype1 = ['real']\n",
    "        varbound = []\n",
    "        vartype = []\n",
    "        for i in range(len(parameters)):\n",
    "            varbound.append(varbound1)\n",
    "            vartype.append(vartype1)\n",
    "        varbound = np.array(varbound)\n",
    "        vartype = np.array( vartype)\n",
    "#         varbound = np.full(shape=len(parameters),fill_value=varbound1)\n",
    "#         print(varbound)\n",
    "#         print(varbound1 for i in range(len(parameters)))\n",
    "        \n",
    "        \n",
    "#         vartype=np.array([['real'],['int'],['int']])\n",
    "        algorithm_param = {'max_num_iteration': n_epochs,\\\n",
    "                           'population_size':100,\\\n",
    "                           'mutation_probability':0.1,\\\n",
    "                           'elit_ratio': 0.1,\\\n",
    "                           'crossover_probability': 0.5,\\\n",
    "                           'parents_portion': 0.3,\\\n",
    "                           'crossover_type':'uniform',\\\n",
    "                           'max_iteration_without_improv':None}\n",
    "        model=ga(function=self.function,dimension=len(parameters),variable_type_mixed=vartype,\n",
    "                 variable_boundaries=varbound, algorithm_parameters = algorithm_param)\n",
    "        model.run()\n",
    "        self.parameters = model.output_dict['variable']\n",
    "        \n",
    "        if verbose_loss == True :\n",
    "            return loss_history\n",
    "    def test(self,X, y):\n",
    "        circuit_copy = self.circuit.copy()\n",
    "        circuit_copy.assign_parameters(self.parameters, inplace=True)\n",
    "        batch_index = np.random.randint(0, len(X), (self.batch_size,))\n",
    "        vector_batch = [X[i] for i in batch_index]\n",
    "        temp_loss = 0\n",
    "        \n",
    "\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            start_qc = QuantumCircuit(2)\n",
    "            start_qc.initialize(X[i], start_qc.qubits[0])\n",
    "            start_qc.initialize(X[i], start_qc.qubits[1])\n",
    "#             start_qc.initialize(X[i])\n",
    "\n",
    "            qc = start_qc + circuit_copy\n",
    "            qc.save_statevector('test1')\n",
    "            qc.measure_all()\n",
    "            qc.save_statevector('test2')\n",
    "\n",
    "            sim = Aer.get_backend('aer_simulator')\n",
    "            qobj = assemble(qc)\n",
    "            job = sim.run(qobj,shots=100)\n",
    "            result = job.result()\n",
    "            data = result.data()\n",
    "            resulting_state = data['test2'].data\n",
    "            temp = self.ham.expectation(resulting_state)/self.num_trash_qubits\n",
    "            y_pred.append(temp.numpy())\n",
    "#             print(resulting_state)\n",
    "#             if y[i] == 1:\n",
    "#                 inliers.append(resulting_state)\n",
    "#             else:\n",
    "#                 outliers.append(resulting_state)\n",
    "# #             temp_loss += self.ham.expectation(resulting_state)/(self.num_trash_qubits*self.batch_size)\n",
    "# #         print(inliers)\n",
    "# #         print(outliers)\n",
    "#         for i in range(len(inliers)):\n",
    "#             if \n",
    "        y_pred = np.around(y_pred)\n",
    "        y_pred[y_pred == 0] = -1\n",
    "#         print(y_pred)\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d51e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
