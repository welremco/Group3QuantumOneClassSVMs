{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc664edf",
   "metadata": {},
   "source": [
    "ZZ Feature Map Algorithm 1 test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35de16c4",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d659b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from qiskit import BasicAer\n",
    "from qiskit import Aer, transpile\n",
    "\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.circuit.library import ZZFeatureMap\n",
    "from qiskit.circuit.library import PauliFeatureMap\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.circuit.library import StatePreparation\n",
    "\n",
    "from qiskit_machine_learning.kernels import QuantumKernel\n",
    "from qiskit_machine_learning.kernels import FidelityQuantumKernel\n",
    "\n",
    "import qiskit_machine_learning.kernels\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import QSVC\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC, OneClassSVM\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import scipy.io\n",
    "import pandas as pd\n",
    "from qiskit.providers.aer import AerError\n",
    "from qiskit_machine_learning.datasets import ad_hoc_data\n",
    "from qiskit.algorithms.state_fidelities import ComputeUncompute\n",
    "algorithm_globals.random_seed = 1\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "\n",
    "from qiskit.algorithms.linear_solvers.numpy_linear_solver import NumPyLinearSolver\n",
    "from qiskit.algorithms.linear_solvers.hhl import HHL\n",
    "from qiskit.quantum_info import DensityMatrix\n",
    "from functools import reduce\n",
    "from sympy import Matrix\n",
    "from sympy import sqrt as special_sqrt\n",
    "from qiskit import *\n",
    "from qiskit.extensions import HamiltonianGate\n",
    "from qiskit.quantum_info import Operator\n",
    "\n",
    "dataset_list = []"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c4a5f750",
   "metadata": {},
   "source": [
    "Code used to generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4925e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(13)\n",
    "seed = 0\n",
    "x, y = make_blobs(n_samples=3, centers=1, cluster_std=.02, center_box=(0.5, 0.5), random_state=seed)\n",
    "\n",
    "out1x, out1y = make_blobs(n_samples=1, centers=1, cluster_std=.01, center_box=(0.6,0.5), random_state=seed)\n",
    "# out2x, out2y = make_blobs(n_samples=11, centers=1, cluster_std=.1, center_box=(3.2, 0.01), random_state=seed)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# prepare data for One-Class model\n",
    "y[y == 0] = 1\n",
    "out1y[out1y==0] = -1 \n",
    "# out2y[out2y==0] = -1 \n",
    "\n",
    "x = np.append(x, out1x, axis = 0)\n",
    "y = np.append(y, out1y, axis = 0)\n",
    "\n",
    "# x = np.append(x, out2x, axis = 0)\n",
    "# y = np.append(y, out2y, axis = 0)\n",
    "\n",
    "# Plot to see data\n",
    "plt.scatter(x[:,0], x[:,1])\n",
    "plt.scatter(out1x[:,0], out1x[:,1])\n",
    "# plt.scatter(out2x[:,0], out2x[:,1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Add data to dataset_list\n",
    "dataset_list.append([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "626d6961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Second dataset: ZZFeatureMap ad_hoc data\n",
    "# adhoc_dimension = 2\n",
    "# train_features, train_labels, test_features, test_labels, adhoc_total = ad_hoc_data(\n",
    "#     training_size=80,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.3,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=True,\n",
    "# )\n",
    "# train_features_out, train_labels_out, _, _ = ad_hoc_data(\n",
    "#     training_size=10,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.6,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "# # adhoc_total[adhoc_total == 0] = 1\n",
    "\n",
    "# # print(train_features)\n",
    "# # print(train_labels)\n",
    "\n",
    "# # Change labels for One-Class\n",
    "# train_labels_out[train_labels_out != -1] = -1\n",
    "\n",
    "# # Now we have to add the outliers\n",
    "# train_features = np.append(train_features, train_features_out, axis = 0)\n",
    "# train_labels = np.append(train_labels, train_labels_out, axis = 0)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(5, 5))\n",
    "# plt.ylim(0, 2 * np.pi)\n",
    "# plt.xlim(0, 2 * np.pi)\n",
    "# plt.imshow(\n",
    "#     np.asmatrix(adhoc_total).T,\n",
    "#     interpolation=\"nearest\",\n",
    "#     origin=\"lower\",\n",
    "#     cmap=\"RdBu\",\n",
    "#     extent=[0, 2 * np.pi, 0, 2 * np.pi],\n",
    "# )\n",
    "\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 0), 0],\n",
    "#     train_features[np.where(train_labels[:] == 0), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"b\",\n",
    "#     label=\"Training Label A\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 1), 0],\n",
    "#     train_features[np.where(train_labels[:] == 1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "#     label=\"Training Label B\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == -1), 0],\n",
    "#     train_features[np.where(train_labels[:] == -1), 1],\n",
    "#     marker=\"s\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"k\",\n",
    "#     label=\"Outliers\",\n",
    "# )\n",
    "\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\", borderaxespad=0.0)\n",
    "# plt.title(\"Ad hoc dataset for classification\")\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # We don't need the second label for one-class SVMs, so change 0 label to 1\n",
    "# train_labels[train_labels == 0] = 1\n",
    "\n",
    "\n",
    "# # add data to dataset_list\n",
    "# dataset_list.append([train_features,train_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e8ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Third dataset, create blob and add zz feature map data to it\n",
    "# random.seed(13)\n",
    "# seed = 23\n",
    "# x, y = make_blobs(n_samples=190, centers=1, cluster_std=3, center_box=(3, 3), random_state=seed)\n",
    "# train_features_out2, train_labels_out2, _, _ = ad_hoc_data(\n",
    "#     training_size=10,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.5,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "\n",
    "# # prepare data for One-Class model\n",
    "# y[y == 0] = 1\n",
    "# train_labels_out2[train_labels_out2 != -1] = -1 \n",
    "\n",
    "# # add outliers to data\n",
    "# x = np.append(x, train_features_out2, axis = 0)\n",
    "# y = np.append(y, train_labels_out2, axis = 0)\n",
    "\n",
    "# # Plot to see data\n",
    "# plt.scatter(x[:,0], x[:,1])\n",
    "# plt.scatter(\n",
    "#     train_features_out2[np.where(train_labels_out2[:] == -1), 0],\n",
    "#     train_features_out2[np.where(train_labels_out2[:] == -1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "#     label=\"Training Label B\",\n",
    "# )\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Add data to dataset_list\n",
    "# dataset_list.append([x,y])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f41d283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adhoc_dimension = 2\n",
    "# train_features, train_labels, _,_ = ad_hoc_data(\n",
    "#     training_size=80,\n",
    "#     test_size=0,\n",
    "#     n=adhoc_dimension,\n",
    "#     gap=0.6,\n",
    "#     plot_data=False,\n",
    "#     one_hot=False,\n",
    "#     include_sample_total=False,\n",
    "# )\n",
    "# x, y = make_blobs(n_samples=20, centers=3, cluster_std=2, center_box=(3, 3), random_state=111)\n",
    "\n",
    "# # prepare data for One-Class model\n",
    "# train_labels[train_labels == 0] = 1\n",
    "# y[y != -1] = -1 \n",
    "\n",
    "# # add outliers to data\n",
    "# train_features = np.append(train_features, x, axis = 0)\n",
    "# train_labels = np.append(train_labels, y, axis = 0)\n",
    "\n",
    "# # Plot to see data\n",
    "# plt.scatter(\n",
    "#     train_features[np.where(train_labels[:] == 1), 0],\n",
    "#     train_features[np.where(train_labels[:] == 1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"b\",\n",
    "#     label=\"Training Label A\",\n",
    "# )\n",
    "# plt.scatter(\n",
    "#     x[np.where(y[:] == -1), 0],\n",
    "#     x[np.where(y[:] == -1), 1],\n",
    "#     marker=\"o\",\n",
    "#     facecolors=\"w\",\n",
    "#     edgecolors=\"r\",\n",
    "# )\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# # Add data to dataset_list\n",
    "# dataset_list.append([train_features,train_labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1094a8ae",
   "metadata": {},
   "source": [
    "Save/Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00d2a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as fileload:\n",
    "        file = pickle.load(fileload)\n",
    "    return file\n",
    "# save_object(dataset_list, \"datasets_small\")\n",
    "dataset_list = load_object(\"datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e6703d",
   "metadata": {},
   "source": [
    "Custom Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb8aaabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_data_map_func(x):\n",
    "    mapped = x[0] if len(x) == 1 else reduce(lambda m, n: m * n, x)\n",
    "    return mapped\n",
    "def feature_map_superfidel(x):\n",
    "    # as described in \n",
    "    # https://doi.org/10.1103/PhysRevA.97.042315\n",
    "    \n",
    "    # Qiskit currently doesn't natively support a square root function in a parameter expression\n",
    "    # So use sympy base to get the same effect\n",
    "    mapped = x[0] if len(x) == 1 else reduce(lambda m, n: m * n, \n",
    "                                             np.divide(x,(1-np.square(np.column_stack(x)).trace())._call(special_sqrt)))\n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9e32a7",
   "metadata": {},
   "source": [
    "Quantum Function for OneClass (Algorithm 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f58ba946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First algorithm, returns trained model\n",
    "def Algorithm1(X, y, reps=2, shots=1, outliers_fraction=20/210,\n",
    "               entanglement=\"linear\", num_features = 2, seed = 0, \n",
    "               supervised=False, feature_map_no = 1, data_map_no = 1, paulis = [\"Z\", \"ZZ\"]) :\n",
    "    if feature_map_no == 1:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        if data_map_no == 1:\n",
    "             feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement)\n",
    "        elif data_map_no == 2:\n",
    "            feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement, \n",
    "                                       data_map_func = custom_data_map_func)\n",
    "        elif data_map_no == 3:\n",
    "            feature_map = ZZFeatureMap(feature_dimension = num_features, \n",
    "                                   reps = reps, entanglement=entanglement, \n",
    "                                       data_map_func = feature_map_superfidel)\n",
    "    elif feature_map_no == 2:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        feature_map = ZFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "    elif feature_map_no == 3:\n",
    "        # Define ZZFeatureMap using inputs\n",
    "        feature_map = PauliFeatureMap(feature_dimension = num_features, reps = reps, paulis=paulis)\n",
    "    # Calculates probabilities of bit results from quantum circuits\n",
    "    sampler = Sampler()\n",
    "    # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    # Translates data with base state fidelity distance metric\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    # Kernel needs to be evaluated before going into the One-Class SVM\n",
    "    svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "    if supervised: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=seed)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        # TODO save to Matrix\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "#         print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "#         print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "    else: \n",
    "        svm.fit(X)\n",
    "        y_pred = svm.predict(X)\n",
    "        #TODO save to matrix\n",
    "#         print(classification_report(y, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba0a968",
   "metadata": {},
   "source": [
    "Showcase of Algorithm 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bba916",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dataset: 1\n",
      "\n",
      "For pauli matrix: ['X', 'XX']\n",
      "[LibSVM]Accuracy: 0.9095238095238095\n",
      "Precision 1: 0.9476439790575916\n",
      "Precision -1: 0.5263157894736842\n",
      "Recall 1: 0.7263157894736842\n",
      "F1 1: 0.7314758732081567\n",
      "F1 1: 0.9501312335958004\n",
      "F1 -1: 0.5128205128205129\n",
      "For pauli matrix: ['Y', 'XX']\n",
      "[LibSVM]"
     ]
    }
   ],
   "source": [
    "dataset_count = 0\n",
    "outliers_fraction=20/210\n",
    "entanglement_list = [\"full\", 'linear']\n",
    "data_map_list = []\n",
    "# for X, y in dataset_list:\n",
    "#     dataset_count = dataset_count + 1\n",
    "#     print()\n",
    "#     print(\"For dataset: {}\".format(dataset_count))\n",
    "#     print()\n",
    "# #     if dataset_count == 2:\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2)\n",
    "# #     if dataset_count == 3:\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2, data_map_no=2)\n",
    "# #     if dataset_count == 4:\n",
    "#         # THIS One is slightly better\n",
    "# #         Algorithm1(X, y, reps=3, feature_map_no=2, data_map_no=3)\n",
    "#     Algorithm1(X, y, reps=4)\n",
    "#     print()\n",
    "#     print(\"For dataset: {}\".format(dataset_count))\n",
    "#     print()\n",
    "#     print(\"Experiment with number of repetitions 1,2,3\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For reps: {}\".format(i))\n",
    "#         Algorithm1(X, y, reps=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different Feature maps\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For feature_map: {}\".format(i))\n",
    "#         Algorithm1(X, y, feature_map_no=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different entanglements\")\n",
    "#     for i in entanglement_list:\n",
    "#         print(\"For entanglement: {}\".format(i))\n",
    "#         Algorithm1(X, y, entanglement=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different data_maps\")\n",
    "#     for i in range(1,4):\n",
    "#         print(\"For data_map: {}\".format(i))\n",
    "#         Algorithm1(X, y, data_map_no=i)\n",
    "#     print()\n",
    "#     print(\"Experiment with different shots\")\n",
    "#     for i in range(1,5,2):\n",
    "#         print(\"For shots: {}\".format(i))\n",
    "#         Algorithm1(X, y, shots=i)\n",
    "\n",
    "# fit data to OneClassSVM\n",
    "# svm.fit(precomp_kernel_real)\n",
    "Pmatrices = [\"X\", \"Y\", \"Z\"]\n",
    "paulis_list = []\n",
    "def combp(pm, prefix, n, k, fullermatrix):\n",
    "    if (k == 0) :\n",
    "        fullermatrix.append(prefix)\n",
    "        return fullermatrix\n",
    "    for i in range(n):\n",
    "        newPrefix = prefix + pm[i]\n",
    "        combp(pm, newPrefix, n, k - 1, fullermatrix)\n",
    "    return fullermatrix\n",
    "paulis_list = combp(Pmatrices,\"\",len(Pmatrices),2,paulis_list)\n",
    "secondpaulis_list = []\n",
    "for e in paulis_list:\n",
    "    for i in Pmatrices:\n",
    "        secondpaulis_list.append([i,e])\n",
    "secondpaulis_list.append([\"I\", \"II\"])\n",
    "\n",
    "\n",
    "\n",
    "# Experiment with Pauli Matrices here\n",
    "for X, y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print()\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    print()\n",
    "    for m in secondpaulis_list:\n",
    "        print(\"For pauli matrix: {}\".format(m))\n",
    "        Algorithm1(X, y, feature_map_no=3, paulis=m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22168876",
   "metadata": {},
   "source": [
    "Comparison to other One-Class SVM methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21e8057e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dataset: 1\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8904761904761904\n",
      "Precision 1: 0.93717277486911\n",
      "Precision -1: 0.42105263157894735\n",
      "Recall 1: 0.6710526315789473\n",
      "F1 1: 0.6749444780940843\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.9714285714285714\n",
      "Precision 1: 0.9842105263157894\n",
      "Precision -1: 0.85\n",
      "Recall 1: 0.9171052631578946\n",
      "F1 1: 0.9171052631578946\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.9714285714285714\n",
      "Precision 1: 0.9842105263157894\n",
      "Precision -1: 0.85\n",
      "Recall 1: 0.9171052631578946\n",
      "F1 1: 0.9171052631578946\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.09523809523809523\n",
      "Precision 1: 0.0\n",
      "Precision -1: 0.09523809523809523\n",
      "Recall 1: 0.5\n",
      "F1 1: 0.08695652173913042\n",
      "\n",
      "For dataset: 2\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8444444444444444\n",
      "Precision 1: 0.9074074074074074\n",
      "Precision -1: 0.2777777777777778\n",
      "Recall 1: 0.584375\n",
      "F1 1: 0.5881006864988558\n",
      "\n",
      "For dataset: 3\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.7904761904761904\n",
      "Precision 1: 0.8924731182795699\n",
      "Precision -1: 0.0\n",
      "Recall 1: 0.4368421052631579\n",
      "F1 1: 0.44148936170212766\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.6047619047619047\n",
      "Precision 1: 0.9212598425196851\n",
      "Precision -1: 0.12048192771084337\n",
      "Recall 1: 0.5578947368421052\n",
      "F1 1: 0.466172552142354\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.6619047619047619\n",
      "Precision 1: 0.9103448275862069\n",
      "Precision -1: 0.1076923076923077\n",
      "Recall 1: 0.5223684210526316\n",
      "F1 1: 0.4763827919227393\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8095238095238095\n",
      "Precision 1: 0.8947368421052632\n",
      "Precision -1: 0.0\n",
      "Recall 1: 0.4473684210526316\n",
      "F1 1: 0.4473684210526316\n",
      "\n",
      "For dataset: 4\n",
      "[LibSVM]rbf: \n",
      "Accuracy: 0.8555555555555555\n",
      "Precision 1: 0.9085365853658537\n",
      "Precision -1: 0.3125\n",
      "Recall 1: 0.590625\n",
      "F1 1: 0.5987654320987654\n",
      "[LibSVM]linear: \n",
      "Accuracy: 0.8333333333333334\n",
      "Precision 1: 0.8963414634146342\n",
      "Precision -1: 0.1875\n",
      "Recall 1: 0.5343749999999999\n",
      "F1 1: 0.537037037037037\n",
      "[LibSVM]poly: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n",
      "[LibSVM]sigmoid: \n",
      "Accuracy: 0.8277777777777777\n",
      "Precision 1: 0.8957055214723927\n",
      "Precision -1: 0.17647058823529413\n",
      "Recall 1: 0.53125\n",
      "F1 1: 0.5330934649820098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "other_kernel_list = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "outliers_fraction=20/210\n",
    "dataset_count = 0\n",
    "supervised = False\n",
    "for X,y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print()\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    for kernel in other_kernel_list:\n",
    "        svm_classical = OneClassSVM(kernel = kernel, verbose=True,  nu=outliers_fraction)\n",
    "        if supervised:\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=0)\n",
    "            svm_classical.fit(X_train, y_train)\n",
    "            y_pred = svm_classical.predict(X_test)\n",
    "            # TODO save to Matrix\n",
    "            print(\"{}: \".format(kernel))\n",
    "#             print(classification_report(y_test, y_pred))\n",
    "            print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "            \n",
    "            print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "            print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "            print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='macro')))\n",
    "            print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "            \n",
    "#             print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "#             print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "#             print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "#             print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        else:\n",
    "            svm_classical.fit(X)\n",
    "            y_pred = svm_classical.predict(X)\n",
    "            # TODO save to Matrix\n",
    "\n",
    "            print(\"{}: \".format(kernel))\n",
    "#             print(classification_report(y, y_pred))\n",
    "            print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "            \n",
    "            print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "            print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "            print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "            print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "#             print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#             print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "            \n",
    "#             print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "#             print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4480e331",
   "metadata": {},
   "source": [
    "Second algorithm function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e969bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def K(x,z, p_constant=1.0):\n",
    "    return (np.dot(x.T,z)+p_constant)**2\n",
    "\n",
    "def Algorithm2(X, y, reps=1, shots=1, outliers_fraction=1/4,entanglement=\"linear\", num_features = 2, seed = 0, supervised=False):\n",
    "    # Qiskit code for RawFeatureVector has bug, currently not in use\n",
    "    # TODO We should use RawFeatureVector to stay true to the paper, but Qiskit currently has problem with this method\n",
    "#     feature_map = RawFeatureVector(feature_dimension = num_features)\n",
    "#     print(feature_map.parameters)\n",
    "#     par0 = feature_map.parameters[0]\n",
    "#     par1 = feature_map.parameters[1]\n",
    "#     print(par0)\n",
    "#     print(par1)\n",
    "#     state = np.array([1, 1]) / np.sqrt(2)\n",
    "#     feature_map = feature_map.assign_parameters(state)\n",
    "#     theta_range = np.linspace(0, 2 * np.pi, 128)\n",
    "#     print(feature_map.parameters)\n",
    "#     feature_map = feature_map.bind_parameters({par0: 1/np.sqrt(2), par1: 1/np.sqrt(2)})\n",
    "#     feature_map = ZZFeatureMap(feature_dimension = num_features, reps = reps, entanglement=entanglement)\n",
    "#     feature_map = ZFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "#     feature_map = PauliFeatureMap(feature_dimension = num_features, reps = reps)\n",
    "\n",
    "#     # Calculates probabilities of bit results from quantum circuits\n",
    "#     sampler = Sampler()\n",
    "#     # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "#     fidelity = ComputeUncompute(sampler=sampler)\n",
    "#     # Translates data with base state fidelity distance metric\n",
    "#     kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "#     # Kernel needs to be evaluated before going into the One-Class SVM\n",
    "\n",
    "#     # Algorithm 2 starts here \n",
    "#     svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "# #     classical_solution = NumPyLinearSolver().solve(X, y / np.linalg.norm(y))\n",
    "\n",
    "    # Trick to make matrix hermitian\n",
    "#     X = np.matrix(X)\n",
    "#     Xh = X.getH()\n",
    "#     zeroes1 = np.zeros((X.shape[0], X.shape[0]))\n",
    "#     zeroes2 = np.zeros((X.shape[1], X.shape[1]))\n",
    "    \n",
    "#     X = np.bmat([[zeroes1, X], [Xh, zeroes2]])\n",
    "#     y = np.append(y, [1,1])\n",
    "#     X = DensityMatrix(X)\n",
    "#     np.real(X)\n",
    "#     print(X)\n",
    "#     hhl = HHL()\n",
    "#     hhl.construct_circuit(X,y)\n",
    "#     inversed_matrix = hhl.solve(X,y)\n",
    "#     X = X[:128]\n",
    "#     y = y[:128]\n",
    "    # Calculate Kernel Matrix\n",
    "    K = np.dot(X, np.transpose(X))\n",
    "    \n",
    "    # Change Kernel Matrix to density matrix gram\n",
    "    K_ = np.divide(K, K.trace())\n",
    "    \n",
    "    # density matrix exponentiation technique\n",
    "    # First make matrix hermitian\n",
    "    K_ = np.matrix(K_)\n",
    "    K_h = K_.getH()\n",
    "    zeroes1 = np.zeros((K_.shape[0], K_.shape[0]))\n",
    "    zeroes2 = np.zeros((K_.shape[1], K_.shape[1]))\n",
    "    \n",
    "    hermitian_K = np.bmat([[zeroes1, K_], [K_h, zeroes2]])\n",
    "    \n",
    "   \n",
    "#     y = np.append(y, [1,1])\n",
    "    \n",
    "    \n",
    "#     K_dense = DensityMatrix(K_)\n",
    "#     K_q = Operator(K_)\n",
    "#     print(K_q)\n",
    "#     K_q = K_q.to_instruction()\n",
    "#     h = HamiltonianGate(hermitian_K, 1)\n",
    "#     print(len(K_))\n",
    "#     print(len(X))\n",
    "    \n",
    "    zeroesy = np.zeros(len(hermitian_K)-len(y))\n",
    "    new_y = np.append(y,zeroesy)\n",
    "    # invert Kernel Matrix\n",
    "    sim_mps = Aer.get_backend('aer_simulator_matrix_product_state')\n",
    "    classical_solution = NumPyLinearSolver().solve(hermitian_K, new_y / np.linalg.norm(new_y))\n",
    "    print(classical_solution)\n",
    "    return\n",
    "    hhl = HHL(epsilon=1, quantum_instance=sim_mps)\n",
    "    circuit_hhl = hhl.construct_circuit(hermitian_K,new_y, neg_vals=False)\n",
    "#     hhl0 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=0)\n",
    "#     hhl1 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=1)\n",
    "#     hhl2 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=2)\n",
    "#     hhl3 =  transpile(hhl, backend=sim_mps, seed_transpiler=11, optimization_level=3)\n",
    "    print(circuit_hhl.decompose())\n",
    "    print(hhl0.decompose())\n",
    "    print(hhl1.decompose())\n",
    "    print(hhl2.decompose())\n",
    "    print(hhl3.decompose())\n",
    "\n",
    "#     inversed_matrix = hhl.solve(hermitian_K,new_y)\n",
    "    print(inversed_matrix)\n",
    "    print(inversed_matrix.observable)\n",
    "    return\n",
    "    # Test with custom feature map\n",
    "    feature_map = PauliFeatureMap(feature_dimension=2, reps=reps, data_map_func=feature_map_superfidel)\n",
    "    # Calculates probabilities of bit results from quantum circuits\n",
    "    sampler = Sampler()\n",
    "    # uses sampler to calculate state fidelity of 2 quantum circuits\n",
    "    fidelity = ComputeUncompute(sampler=sampler)\n",
    "    # Translates data with base state fidelity distance metric\n",
    "    kernel = FidelityQuantumKernel(fidelity=fidelity, feature_map=feature_map)\n",
    "    svm = OneClassSVM(kernel = kernel.evaluate, verbose=True, nu=outliers_fraction)\n",
    "\n",
    "    if supervised: \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=seed)\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        # TODO save to Matrix\n",
    "#         print(classification_report(y_test, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y_test, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y_test, y_pred, average='binary')))\n",
    "        print(\"Recall -1: {}\".format(recall_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y_test, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y_test, y_pred, pos_label=-1, average='binary')))\n",
    "    else: \n",
    "        svm.fit(X)\n",
    "        y_pred = svm.predict(X)\n",
    "        #TODO save to matrix\n",
    "#         print(classification_report(y, y_pred))\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "        print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "    return svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e4ed2",
   "metadata": {},
   "source": [
    "Second algorithm attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d237a704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For dataset: 1\n",
      "For reps: 2\n",
      "{   'circuit_results': None,\n",
      "    'euclidean_norm': 5.208533804241974e+16,\n",
      "    'observable': None,\n",
      "    'state': array([ 0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
      "        1.64626730e+16, -2.50993237e+15,  2.85064745e+16, -4.02857790e+16])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\AppData\\Local\\Temp/ipykernel_8420/1911906896.py:81: DeprecationWarning: The NumPyLinearSolver class is deprecated as of Qiskit Terra 0.22.0 and will be removed no sooner than 3 months after the release date. \n",
      "  classical_solution = NumPyLinearSolver().solve(hermitian_K, new_y / np.linalg.norm(new_y))\n"
     ]
    }
   ],
   "source": [
    "dataset_count = 0\n",
    "outliers_fraction=1/4\n",
    "# MAKE SMALL DATASET\n",
    "for X, y in dataset_list:\n",
    "    dataset_count = dataset_count + 1\n",
    "    print(\"For dataset: {}\".format(dataset_count))\n",
    "    for i in range(2,3):\n",
    "        print(\"For reps: {}\".format(i))\n",
    "        Algorithm2(X, y, i, 1, outliers_fraction=outliers_fraction)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8e8b0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 929.252x144.48 with 1 Axes>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "feature_map = ZZFeatureMap(feature_dimension = 2, reps = 2)\n",
    "feature_map.decompose().draw('mpl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9a5d2b",
   "metadata": {},
   "source": [
    "$$\\phi_S:\\mathbf{x}\\mapsto \\Bigg\\{\\begin{array}{ll}\n",
    "    x_i & \\mbox{if}\\ S=\\{i\\} \\\\\n",
    "        \\cos(\\pi+x_i)\\cos(\\pi+x_j) & \\mbox{if}\\ S=\\{i,j\\}\n",
    "    \\end{array}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ed9a9",
   "metadata": {},
   "source": [
    "Quantum Auto Encoder Implementation in Qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "437d0f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.circuit import QuantumCircuit, Parameter\n",
    "from itertools import combinations\n",
    "from qibo import hamiltonians\n",
    "from qiskit.opflow import Z, I, StateFn, CircuitStateFn, SummedOp\n",
    "from qiskit.opflow import X as X_gate\n",
    "from qiskit.opflow.gradients import Gradient, NaturalGradient, QFI, Hessian\n",
    "from qiskit.circuit import QuantumCircuit, QuantumRegister, Parameter, ParameterVector, ParameterExpression\n",
    "from qiskit.circuit.library import EfficientSU2\n",
    "\n",
    "def Quantum_Autoencoder_circuit(parameters, num_qubits, num_trash_qubits, layers, num_parameters):\n",
    "    circuit = QuantumCircuit(num_qubits)\n",
    "    paramidx = 0\n",
    "    if (num_trash_qubits <= num_qubits/2):\n",
    "        for l in range(layers):\n",
    "            for idx in range(num_trash_qubits):\n",
    "                for q in range(num_qubits):\n",
    "                    #phase rotation\n",
    "                    temp_parameter = Parameter('{}'.format(paramidx))\n",
    "                    circuit.ry(temp_parameter,q)\n",
    "                    circuit.assign_parameters({temp_parameter: parameters[q+idx*num_qubits+l*num_trash_qubits*num_qubits]})\n",
    "                    paramidx += 1\n",
    "                # CZ between trash qubits\n",
    "                for i,j in combinations(range(num_qubits-num_trash_qubits,num_qubits),2):\n",
    "                    circuit.cz(i,j)\n",
    "                # CZ between trash and non-trash qubits\n",
    "                for i in range(num_trash_qubits):\n",
    "                    for j in range(i,num_qubits-num_trash_qubits,num_trash_qubits):\n",
    "                        circuit.cz(num_qubits-num_trash_qubits+((idx+i)%num_trash_qubits),j)\n",
    "    else :\n",
    "        for l in range(layers):\n",
    "            for idx in range(num_qubits-num_trash_qubits):\n",
    "                for q in range(num_qubits):\n",
    "                    #phase rotation\n",
    "                    temp_parameter = Parameter('{}'.format(paramidx))\n",
    "                    circuit.ry(temp_parameter,q)\n",
    "#                     circuit.ry(parameters[q+idx*num_qubits+l*(num_qubits-num_trash_qubits)*num_qubits],q)\n",
    "                    circuit.assign_parameters({temp_parameter: parameters[q+idx*num_qubits+l*(num_qubits-num_trash_qubits)*num_qubits]})\n",
    "                    paramidx += 1\n",
    "                # CZ between trash qubits\n",
    "                for i,j in combinations(range(num_qubits-num_trash_qubits,num_qubits),2):\n",
    "                    circuit.cz(i,j)\n",
    "                for i in range(num_qubits-num_trash_qubits):\n",
    "                    for j in range(num_qubits-num_trash_qubits+i,num_qubits,num_qubits-num_trash_qubits):\n",
    "                        circuit.cz((idx+i)%(num_qubits-num_trash_qubits),j)\n",
    "    for q in range(num_trash_qubits):\n",
    "        temp_parameter = Parameter('{}'.format(paramidx))\n",
    "        circuit.ry(temp_parameter,q)\n",
    "#         circuit.ry(parameters[num_parameters-num_trash_qubits+q], num_qubits-num_trash_qubits+q)\n",
    "        circuit.assign_parameters({temp_parameter: parameters[num_parameters-num_trash_qubits+q]})\n",
    "        paramidx += 1\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "#TODO\n",
    "def cost_hamiltonian(num_qubits, num_trash_qubits):\n",
    "    '''\n",
    "    Hamiltonian for evaluating Hamming distance based Cost function\n",
    "    '''\n",
    "    num_trash_qubits = num_trash_qubits \n",
    "#     print(num_trash_qubits)\n",
    "#     print(hamiltonians.Z(num_trash_qubits))\n",
    "#     print(hamiltonians.Z(num_trash_qubits).matrix)\n",
    "    m0 = hamiltonians.Z(num_trash_qubits).matrix.numpy()\n",
    "    m1 = np.eye(2 ** (num_qubits - num_trash_qubits), dtype=m0.dtype)\n",
    "    ham = hamiltonians.Hamiltonian(num_qubits, np.kron(m1, m0))\n",
    "#     print(0.5 * (ham + num_trash_qubits))\n",
    "    \n",
    "#     a = Parameter('a')\n",
    "#     b = Parameter('b')\n",
    "#     q = QuantumRegister(1)\n",
    "#     qc = QuantumCircuit(q)\n",
    "#     qc.h(q)\n",
    "#     qc.rz(a, q[0])\n",
    "#     qc.rx(b, q[0])\n",
    "#     H = (2 * X) + Z\n",
    "    return 0.5 * (ham + num_trash_qubits)\n",
    "\n",
    "def data_encoding(X, encoding):\n",
    "    '''\n",
    "        --------\n",
    "        Args :\n",
    "            dataset : Dataset for one-class classification \"Handwritten\" or \"FMNIST\"\n",
    "            encoding : Data encoding method \"Amplitude\"(Amplitude encoding) or \"FRQI\"(FRQI encoding)\n",
    "            idx : Index of the positive data to be trained/tested for one-class classification\n",
    "        --------\n",
    "        Return :\n",
    "            encoded_X : train dataset with the positive data\n",
    "            num_qubits : the number of qubits required for the given data encoding\n",
    "    '''\n",
    "\n",
    "    encoded_X = []\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    if encoding == \"Amplitude\":\n",
    "        num_qubits = 2\n",
    "        for i in range(len(X)):\n",
    "            encoded_X.append(np.array(X[i])/np.linalg.norm(np.array(X[i])))\n",
    "    if encoding == \"FRQI\":\n",
    "        num_qubits = 2\n",
    "        for i in range(len(X)):\n",
    "            vector = np.concatenate((np.cos(np.pi/2*np.array(X[i])),np.sin(np.pi/2*np.array(X[i]))))/8.0\n",
    "            encoded_X.append(vector/np.linalg.norm(np.array(vector)))  \n",
    "#         print(new_X)\n",
    "#         print(X)\n",
    "#     elif encoding == \"FRQI\":\n",
    "#         nqubits = 7 # number of qubits\n",
    "#         digit_pos = digit_pos/16.0\n",
    "#         # Data Encoding FRQI\n",
    "#         for i in range(100):\n",
    "#             vector = np.concatenate((np.cos(np.pi/2*np.array(digit_pos[i])),np.sin(np.pi/2*np.array(digit_pos[i]))))/8.0\n",
    "#             vector_train.append(vector/np.linalg.norm(np.array(vector)))\n",
    "#         for i in range(100,170):\n",
    "#             vector = np.concatenate((np.cos(np.pi/2*np.array(digit_pos[i])),np.sin(np.pi/2*np.array(digit_pos[i]))))/8.0\n",
    "#             vector_test_pos.append(vector/np.linalg.norm(np.array(vector)))\n",
    "#         for idx_neg in neg_list:\n",
    "#             digit_neg = digits.data[np.where(digits.target == idx_neg)]/16.0\n",
    "#             for i in range(70):\n",
    "#                 vector = np.concatenate((np.cos(np.pi/2*np.array(digit_neg[i])),np.sin(np.pi/2*np.array(digit_neg[i]))))/8.0\n",
    "#                 vector_test_neg.append(vector/np.linalg.norm(np.array(vector)))\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Only Amplitude and FRQI encoding is supported\"\n",
    "        )\n",
    "    \n",
    "    \n",
    "    return encoded_X, num_qubits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af78d154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "class VQOCC(): \n",
    "    def __init__(self, num_qubits, num_trash_qubits, layers):\n",
    "        '''\n",
    "        Variational Quantum One-Class Classifier\n",
    "        --------\n",
    "        Args :\n",
    "            num_qubits : The number of qubits\n",
    "            num_trash_qubits : The number of trash qubits\n",
    "            layers : The number of parameterized quantum circuit layers\n",
    "        --------\n",
    "        '''\n",
    "        assert num_trash_qubits < num_qubits\n",
    "\n",
    "        self.num_qubits = num_qubits\n",
    "        self.num_trash_qubits = num_trash_qubits\n",
    "        self.layers = layers\n",
    "\n",
    "        if (num_trash_qubits <= num_qubits/2):\n",
    "            num_parameters = num_trash_qubits * (num_qubits * layers + 1)\n",
    "        else:\n",
    "            num_parameters = (num_qubits-num_trash_qubits)*num_qubits*layers + num_trash_qubits\n",
    "\n",
    "        self.num_parameters = num_parameters\n",
    "        self.parameters = np.random.uniform(low=0.0, high=1.0, size=(num_parameters,))\n",
    "        self.circuit = Quantum_Autoencoder_circuit(self.parameters, num_qubits, num_trash_qubits, layers, num_parameters)\n",
    "     \n",
    "    def function(self, parameters):\n",
    "        circuit_copy = self.circuit.copy()\n",
    "\n",
    "        circuit_copy.assign_parameters(parameters, inplace=True)\n",
    "\n",
    "    #             print(parameters)\n",
    "        batch_index = np.random.randint(0, len(self.X), (self.batch_size,))\n",
    "        vector_batch = [self.X[i] for i in batch_index]\n",
    "        temp_loss = 0\n",
    "        for i in range(self.batch_size):\n",
    "    #                 circuit_copy = circuit.copy()\n",
    "    #             for i in range(len(X)-1):\n",
    "            start_qc = QuantumCircuit(2)\n",
    "#             start_qc.initialize(self.X[i], start_qc.qubits[0])\n",
    "#             start_qc.initialize(self.X[i], start_qc.qubits[1])\n",
    "            start_qc.initialize(self.X[i])\n",
    "    \n",
    "            qc = start_qc + circuit_copy\n",
    "            qc.save_statevector('test1')\n",
    "            qc.measure_all()\n",
    "            qc.save_statevector('test2')\n",
    "\n",
    "            sim = Aer.get_backend('aer_simulator')\n",
    "            qobj = assemble(qc)\n",
    "            job = sim.run(qobj,shots=1024)\n",
    "            result = job.result()\n",
    "            data = result.data()\n",
    "            resulting_state = data['test2'].data\n",
    "            temp_loss += self.ham.expectation(resulting_state)/(self.num_trash_qubits*self.batch_size)\n",
    "        return temp_loss\n",
    "    def train(self,X,lr=0.1,n_epochs=150,batch_size=10,verbose_loss=False):\n",
    "        '''\n",
    "        --------\n",
    "        Args :\n",
    "            X :  dataset\n",
    "            lr : Learning rate\n",
    "            n_epochs : The number of training epochs\n",
    "            batch_size : The size of batch for Training\n",
    "            verbose_loss : returning the loss history\n",
    "        --------\n",
    "        '''\n",
    "#         criterion = nn.CrossEntropyLoss()\n",
    "#         parameter_tensor = [torch.tensor(self.parameters, requires_grad=True)]\n",
    "#         optimizer = optim.Adam(parameter_tensor , lr=lr)\n",
    "#         print(parameter_tensor[0].detach().numpy())\n",
    "\n",
    "        parameters = self.parameters\n",
    "        best_parameters = self.parameters\n",
    "        loss_history = []\n",
    "        num_trash_qubits = self.num_trash_qubits\n",
    "        self.batch_size = batch_size\n",
    "        circuit = self.circuit.copy()\n",
    "        self.X = X\n",
    "        self.ham = cost_hamiltonian(self.num_qubits,num_trash_qubits)\n",
    "#         print(type(ham))\n",
    "        loss = 1\n",
    "#         for e in range(n_epochs):\n",
    "#             # Training Quantum circuit with loss functions evaluated from Hamiltonian\n",
    "#             # using automatic differentiation\n",
    "# #             print(len(parameters))\n",
    "#             circuit_copy = circuit.copy()\n",
    "    \n",
    "# #             circuit_copy.assign_parameters(parameter_tensor[0].detach().numpy(), inplace=True)\n",
    "#             circuit_copy.assign_parameters(parameters, inplace=True)\n",
    "\n",
    "# #             print(parameters)\n",
    "#             batch_index = np.random.randint(0, len(X), (batch_size,))\n",
    "#             vector_batch = [X[i] for i in batch_index]\n",
    "#             temp_loss = 0\n",
    "#             for i in range(batch_size):\n",
    "# #                 circuit_copy = circuit.copy()\n",
    "# #             for i in range(len(X)-1):\n",
    "#                 start_qc = QuantumCircuit(2)\n",
    "#                 start_qc.initialize(encoded_X[i], start_qc.qubits[0])\n",
    "#                 start_qc.initialize(encoded_X[i], start_qc.qubits[1])\n",
    "#                 qc = start_qc + circuit_copy\n",
    "#                 qc.save_statevector('test1')\n",
    "#                 qc.measure_all()\n",
    "#                 qc.save_statevector('test2')\n",
    "\n",
    "#                 sim = Aer.get_backend('aer_simulator')\n",
    "#                 qobj = assemble(qc)\n",
    "#                 job = sim.run(qobj,shots=1024)\n",
    "#                 result = job.result()\n",
    "#                 data = result.data()\n",
    "#                 resulting_state = data['test1'].data\n",
    "#                 temp_loss += self.ham.expectation(resulting_state)/(num_trash_qubits*batch_size)\n",
    "            \n",
    "# #             optimizer.zero_grad()\n",
    "# #             loss = torch.tensor(temp_loss.numpy(), requires_grad=True)\n",
    "# #             loss.backward()\n",
    "# #             print(parameter_tensor[0].grad)\n",
    "\n",
    "#             if temp_loss < loss:\n",
    "#                 loss = temp_loss\n",
    "#                 best_parameters = parameters\n",
    "#             else:\n",
    "#                 parameters = np.random.uniform(low=0.0, high=1.0, size=(len(parameters),))\n",
    "# #             loss = temp_loss\n",
    "#             print(loss)\n",
    "#             #TODO Calculate loss/parameter gradients\n",
    "            \n",
    "#             #TODO Apply gradients to parameters, and update them\n",
    "# #             print(optimizer)\n",
    "            \n",
    "#             loss_history.append(loss)\n",
    "            \n",
    "            \n",
    "        \n",
    "            \n",
    "        varbound1 = [0.0,1.0]\n",
    "        vartype1 = ['real']\n",
    "        varbound = []\n",
    "        vartype = []\n",
    "        for i in range(len(parameters)):\n",
    "            varbound.append(varbound1)\n",
    "            vartype.append(vartype1)\n",
    "        varbound = np.array(varbound)\n",
    "        vartype = np.array( vartype)\n",
    "#         varbound = np.full(shape=len(parameters),fill_value=varbound1)\n",
    "#         print(varbound)\n",
    "#         print(varbound1 for i in range(len(parameters)))\n",
    "        \n",
    "        \n",
    "#         vartype=np.array([['real'],['int'],['int']])\n",
    "        algorithm_param = {'max_num_iteration': n_epochs,\\\n",
    "                           'population_size':100,\\\n",
    "                           'mutation_probability':0.1,\\\n",
    "                           'elit_ratio': 0.01,\\\n",
    "                           'crossover_probability': 0.5,\\\n",
    "                           'parents_portion': 0.3,\\\n",
    "                           'crossover_type':'uniform',\\\n",
    "                           'max_iteration_without_improv':None}\n",
    "        model=ga(function=self.function,dimension=len(parameters),variable_type_mixed=vartype,\n",
    "                 variable_boundaries=varbound, algorithm_parameters = algorithm_param)\n",
    "        model.run()\n",
    "        print(self.function([0,1,1]))\n",
    "        print('test')\n",
    "        print(model.output_dict['variable'])\n",
    "        self.parameters = model.output_dict['variable']\n",
    "#         self.circuit = circuit_copy\n",
    "        \n",
    "        if verbose_loss == True :\n",
    "            return loss_history\n",
    "    def test(self,X, y):\n",
    "        circuit_copy = self.circuit.copy()\n",
    "        circuit_copy.assign_parameters(self.parameters, inplace=True)\n",
    "        batch_index = np.random.randint(0, len(X), (self.batch_size,))\n",
    "        vector_batch = [X[i] for i in batch_index]\n",
    "        temp_loss = 0\n",
    "        \n",
    "#         inliers = []\n",
    "#         outliers = []\n",
    "        y_pred = []\n",
    "        for i in range(len(X)):\n",
    "            start_qc = QuantumCircuit(2)\n",
    "#             start_qc.initialize(X[i], start_qc.qubits[0])\n",
    "#             start_qc.initialize(X[i], start_qc.qubits[1])\n",
    "            start_qc.initialize(X[i])\n",
    "\n",
    "            qc = start_qc + circuit_copy\n",
    "            qc.save_statevector('test1')\n",
    "            qc.measure_all()\n",
    "            qc.save_statevector('test2')\n",
    "\n",
    "            sim = Aer.get_backend('aer_simulator')\n",
    "            qobj = assemble(qc)\n",
    "            job = sim.run(qobj,shots=1024)\n",
    "            result = job.result()\n",
    "            data = result.data()\n",
    "            resulting_state = data['test2'].data\n",
    "            temp = self.ham.expectation(resulting_state)/self.num_trash_qubits\n",
    "            y_pred.append(temp.numpy())\n",
    "#             print(resulting_state)\n",
    "#             if y[i] == 1:\n",
    "#                 inliers.append(resulting_state)\n",
    "#             else:\n",
    "#                 outliers.append(resulting_state)\n",
    "# #             temp_loss += self.ham.expectation(resulting_state)/(self.num_trash_qubits*self.batch_size)\n",
    "# #         print(inliers)\n",
    "# #         print(outliers)\n",
    "#         for i in range(len(inliers)):\n",
    "#             if \n",
    "        y_pred = np.around(y_pred)\n",
    "        y_pred[y_pred == 0] = -1\n",
    "        print(y_pred)\n",
    "        print(\"Accuracy: {}\".format(accuracy_score(y, y_pred)))\n",
    "\n",
    "        print(\"Precision 1: {}\".format(precision_score(y, y_pred, average='binary')))\n",
    "        print(\"Precision -1: {}\".format(precision_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "        \n",
    "        print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='macro')))\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='macro')))\n",
    "\n",
    "#         print(\"Recall 1: {}\".format(recall_score(y, y_pred, average='binary')))\n",
    "#         print(\"Recall -1: {}\".format(recall_score(y, y_pred, pos_label=-1, average='binary')))\n",
    "\n",
    "        print(\"F1 1: {}\".format(f1_score(y, y_pred, average='binary')))\n",
    "        print(\"F1 -1: {}\".format(f1_score(y, y_pred, pos_label=-1, average='binary')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf7fe932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.29547466 1.52111453]\n",
      " [1.33719124 1.35189729]\n",
      " [1.46433145 1.24293766]\n",
      " [1.34903478 1.35619257]\n",
      " [1.4773253  1.28161194]\n",
      " [1.46252315 1.23979423]\n",
      " [1.54882522 1.58958892]\n",
      " [1.21569304 1.3522026 ]\n",
      " [1.46898182 1.53018462]\n",
      " [1.35444675 1.40174792]\n",
      " [1.28525313 1.356218  ]\n",
      " [1.49208588 1.43187277]\n",
      " [1.34891949 1.28193678]\n",
      " [1.25087424 1.44393917]\n",
      " [1.28731742 1.32693222]\n",
      " [1.28111407 1.34931836]\n",
      " [1.41774261 1.35982191]\n",
      " [1.51523316 1.50796186]\n",
      " [1.58831507 1.26522409]\n",
      " [1.49101789 1.43172182]\n",
      " [1.22441094 1.44509345]\n",
      " [1.29997847 1.24552289]\n",
      " [1.47471883 1.2811055 ]\n",
      " [1.3536404  1.44814815]\n",
      " [1.51787796 1.38200752]\n",
      " [1.31045334 1.43869025]\n",
      " [1.3690987  1.23239962]\n",
      " [1.31387743 1.5910065 ]\n",
      " [1.35968231 1.52224451]\n",
      " [1.38662984 1.50777438]\n",
      " [1.29657572 1.46815945]\n",
      " [1.39843179 1.41609282]\n",
      " [1.26934731 1.56581307]\n",
      " [1.33475914 1.36090466]\n",
      " [1.30555537 1.35899503]\n",
      " [1.43130677 1.31459043]\n",
      " [1.47717906 1.48235042]\n",
      " [1.42745164 1.31090849]\n",
      " [1.32744026 1.2616636 ]\n",
      " [1.33641539 1.46764333]\n",
      " [1.2459203  1.4063262 ]\n",
      " [1.42982382 1.53263859]\n",
      " [1.51394007 1.27651742]\n",
      " [1.63831448 1.49444795]\n",
      " [1.46140794 1.49222067]\n",
      " [1.35203442 1.46203583]\n",
      " [1.41666735 1.46350314]\n",
      " [1.37322665 1.28719887]\n",
      " [1.41549474 1.43781625]\n",
      " [1.34026839 1.37620783]\n",
      " [1.62697546 1.25456343]\n",
      " [1.50685094 1.35466142]\n",
      " [1.5922942  1.54805148]\n",
      " [1.4523891  1.40884221]\n",
      " [1.41565065 1.4232181 ]\n",
      " [1.33256673 1.40318306]\n",
      " [1.33477064 1.34788107]\n",
      " [1.44937418 1.38838961]\n",
      " [1.47290906 1.41289829]\n",
      " [1.61632359 1.53365279]\n",
      " [1.31965903 1.33104502]\n",
      " [1.43563664 1.47065732]\n",
      " [1.40665172 1.43024719]\n",
      " [1.23861022 1.37872597]\n",
      " [1.43960067 1.29069385]\n",
      " [1.51266359 1.29200685]\n",
      " [1.41440436 1.54542735]\n",
      " [1.32803956 1.3187007 ]\n",
      " [1.27745645 1.4844363 ]\n",
      " [1.39578285 1.37131128]\n",
      " [1.4947252  1.38449899]\n",
      " [1.52302907 1.52023798]\n",
      " [1.3362563  1.36027282]\n",
      " [1.3600551  1.43700559]\n",
      " [1.38093465 1.36051505]\n",
      " [1.37319966 1.48024564]\n",
      " [1.26840926 1.35384154]\n",
      " [1.36520879 1.4156349 ]\n",
      " [1.45765908 1.37917012]\n",
      " [1.33054321 1.38503655]\n",
      " [1.38967811 1.44105985]\n",
      " [1.39317584 1.57133427]\n",
      " [1.59559123 1.43900933]\n",
      " [1.53645318 1.33105508]\n",
      " [1.3403686  1.39474327]\n",
      " [1.39829796 1.43791517]\n",
      " [1.3586381  1.32525452]\n",
      " [1.54940791 1.37948417]\n",
      " [1.42799246 1.39018496]\n",
      " [1.63039167 1.29399842]\n",
      " [1.54944845 1.1930015 ]\n",
      " [1.20637202 1.41887786]\n",
      " [1.39383736 1.38926947]\n",
      " [1.45210649 1.3424212 ]\n",
      " [1.51880298 1.43169426]\n",
      " [1.44023416 1.33151899]\n",
      " [1.38894593 1.50201727]\n",
      " [1.2951447  1.25799821]\n",
      " [1.27472046 1.47774904]\n",
      " [1.33563816 1.17765968]\n",
      " [1.33275396 1.36404468]\n",
      " [1.32300839 1.45392492]\n",
      " [1.3260437  1.55430146]\n",
      " [1.40457585 1.38128161]\n",
      " [1.48416313 1.37505414]\n",
      " [1.45785215 1.43496545]\n",
      " [1.23698017 1.44627823]\n",
      " [1.49494208 1.40875512]\n",
      " [1.45232767 1.38284537]\n",
      " [1.39607172 1.28319065]\n",
      " [1.43764255 1.29005992]\n",
      " [1.31292029 1.34211503]\n",
      " [1.46401315 1.2383044 ]\n",
      " [1.46722948 1.44074618]\n",
      " [1.28426447 1.36877077]\n",
      " [1.47610377 1.4121675 ]\n",
      " [1.31868537 1.22737174]\n",
      " [1.39718178 1.44283319]\n",
      " [1.44656624 1.24637563]\n",
      " [1.41269121 1.44019894]\n",
      " [1.50996596 1.46552637]\n",
      " [1.3881836  1.33198218]\n",
      " [1.46984571 1.40037709]\n",
      " [1.32952997 1.49432607]\n",
      " [1.6259309  1.39577428]\n",
      " [1.28956167 1.40521651]\n",
      " [1.27071431 1.42670509]\n",
      " [1.55327792 1.54693588]\n",
      " [1.36460061 1.26250487]\n",
      " [1.4049495  1.44938368]\n",
      " [1.38671194 1.37022091]\n",
      " [1.32358561 1.25622085]\n",
      " [1.40105    1.57858705]\n",
      " [1.42863437 1.46088438]\n",
      " [1.35648464 1.58492637]\n",
      " [1.35019675 1.59295321]\n",
      " [1.29292474 1.50544517]\n",
      " [1.28438176 1.47811981]\n",
      " [1.37930963 1.48801789]\n",
      " [1.34571385 1.441605  ]\n",
      " [1.14470102 1.46536186]\n",
      " [1.39015475 1.33365217]\n",
      " [1.49500884 1.38486428]\n",
      " [1.28268766 1.59436212]\n",
      " [1.35590774 1.37196445]\n",
      " [1.46915388 1.46947491]\n",
      " [1.48568306 1.33489744]\n",
      " [1.25759391 1.35066801]\n",
      " [1.32552452 1.31735615]\n",
      " [1.33159891 1.56595508]\n",
      " [1.49318484 1.4339965 ]\n",
      " [1.41419532 1.36806716]\n",
      " [1.44438632 1.43336743]\n",
      " [1.48644362 1.3257835 ]\n",
      " [1.5867558  1.30227221]\n",
      " [1.36884475 1.40561653]\n",
      " [1.36891138 1.40974002]\n",
      " [1.33121624 1.27859226]\n",
      " [1.46663831 1.35392802]\n",
      " [1.30927016 1.40519454]\n",
      " [1.13408278 1.46063195]\n",
      " [1.31122143 1.20192035]\n",
      " [1.33079502 1.55363771]\n",
      " [1.4786328  1.35335809]\n",
      " [1.3044055  1.36540182]\n",
      " [1.24170616 1.46103794]\n",
      " [1.44262587 1.4676908 ]\n",
      " [1.23018942 1.43872805]\n",
      " [1.39756739 1.32619691]\n",
      " [1.2729515  1.49693967]\n",
      " [1.3842333  1.62567235]\n",
      " [1.4097725  1.45829537]\n",
      " [1.36308182 1.37606208]\n",
      " [1.43990463 1.12274072]\n",
      " [1.19693155 1.60644929]\n",
      " [1.4978738  1.62408932]\n",
      " [1.5867559  1.49060447]\n",
      " [1.4208275  1.4976639 ]\n",
      " [1.36353065 1.41567039]\n",
      " [1.38640503 1.51368914]\n",
      " [1.42804417 1.30068764]\n",
      " [1.33656779 1.36372588]\n",
      " [1.31866357 1.25335757]\n",
      " [1.28348502 1.49008265]\n",
      " [1.26657415 1.26532825]\n",
      " [1.46937732 1.38404266]\n",
      " [1.36126732 1.36976972]\n",
      " [1.30871778 1.51170163]\n",
      " [1.36151202 1.40943516]\n",
      " [1.22937298 1.59507754]\n",
      " [1.03130677 0.91459043]\n",
      " [1.1867558  0.90227221]\n",
      " [1.07610377 1.0121675 ]\n",
      " [1.04438632 1.03336743]\n",
      " [0.98967811 1.04105985]\n",
      " [1.01440436 1.14542735]\n",
      " [1.09500884 0.98486428]\n",
      " [1.14940791 0.97948417]\n",
      " [1.0978738  1.22408932]\n",
      " [1.43896304 0.95960577]\n",
      " [1.19398594 0.98390778]\n",
      " [1.63604072 0.82081813]\n",
      " [1.49367125 0.95191335]\n",
      " [1.53572854 0.84432942]\n",
      " [1.52538869 0.93071342]\n",
      " [1.46368928 1.06397327]\n",
      " [1.48059169 0.83313635]\n",
      " [1.54715872 1.14263524]\n",
      " [1.54429376 0.9034102 ]\n",
      " [1.59869283 0.89803009]]\n",
      "[array([-0.31653315, -0.51630529,  0.63230275,  0.48314475]), array([-0.35725785, -0.37125745,  0.61021867,  0.60180388]), array([-0.47121606, -0.26333437,  0.52721478,  0.6562431 ]), array([-0.36854775, -0.37530935,  0.60346711,  0.59928532]), array([-0.48187798, -0.30269047,  0.51748779,  0.63904497]), array([-0.46971662, -0.26009086,  0.52855113,  0.65753536]), array([-0.53683987, -0.56518818,  0.46022055,  0.42492626]), array([-0.23501743, -0.37154602,  0.6669084 ,  0.60162576]), array([-0.47505464, -0.52313615,  0.52375862,  0.47574002]), array([-0.3736645 , -0.41719603,  0.60031228,  0.57091809]), array([-0.30634057, -0.37533328,  0.63730327,  0.59927033]), array([-0.49374579, -0.4437348 ,  0.50617694,  0.55054467]), array([-0.36843845, -0.30301651,  0.60353385,  0.63889044]), array([-0.27149492, -0.45408942,  0.65290927,  0.54203579]), array([-0.30840546, -0.34737832,  0.63630659,  0.61589634]), array([-0.30219062, -0.36881653,  0.6392815 ,  0.60330288]), array([-0.43140684, -0.37871973,  0.56025721,  0.59713597]), array([-0.51181982, -0.50621396,  0.48789392,  0.49370783]), array([-0.56433679, -0.28614173,  0.42605632,  0.64662424]), array([-0.49289594, -0.44360425,  0.50700453,  0.55064986]), array([-0.24412777, -0.45507145,  0.66362763,  0.54121158]), array([-0.32099845, -0.26599711,  0.63004761,  0.65516833]), array([-0.47975524, -0.30218201,  0.51945636,  0.63928556]), array([-0.37290384, -0.45766311,  0.60078509,  0.53902178]), array([-0.51384232, -0.3992952 ,  0.48576339,  0.58357805]), array([-0.33132127, -0.44960496,  0.62468089,  0.54576129]), array([-0.38738065, -0.25243592,  0.59155408,  0.660512  ]), array([-0.33467634, -0.56613297,  0.62288984,  0.42366669]), array([-0.37858878, -0.51716204,  0.597219  ,  0.48222756]), array([-0.40352185, -0.50606855,  0.58066352,  0.49385688]), array([-0.31762626, -0.47437767,  0.63175435,  0.52437184]), array([-0.4142165 , -0.42995349,  0.5730835 ,  0.56137332]), array([-0.29032372, -0.54892802,  0.64475743,  0.44573314]), array([-0.35492401, -0.37973478,  0.61157906,  0.59649099]), array([-0.3265054 , -0.37794382,  0.62721147,  0.59762737]), array([-0.44324515, -0.33537374,  0.55093896,  0.62251462]), array([-0.48175909, -0.48594768,  0.51759847,  0.51366803]), array([-0.43990076, -0.3317678 ,  0.55361297,  0.62444385]), array([-0.34786971, -0.28252083,  0.61561893,  0.64821445]), array([-0.35651391, -0.4739524 ,  0.61065361,  0.52475625]), array([-0.26640605, -0.421291  ,  0.65500215,  0.56790307]), array([-0.44196058, -0.52496609,  0.55196997,  0.47371997]), array([-0.51082776, -0.29756691,  0.48893251,  0.64144675]), array([-0.59602476, -0.49562047,  0.38046613,  0.5043415 ]), array([-0.46879   , -0.49385295,  0.52937315,  0.50607239]), array([-0.37138707, -0.46931189,  0.60172389,  0.52891053]), array([-0.43045994, -0.4705297 ,  0.56098507,  0.52782743]), array([-0.39120821, -0.30828696,  0.58902983,  0.63636401]), array([-0.42942591, -0.44885527,  0.56177699,  0.54637802]), array([-0.3602032 , -0.39396224,  0.60848472,  0.58719141]), array([-0.58915399, -0.27527393,  0.39102119,  0.65132501]), array([-0.50535166, -0.37386691,  0.49459044,  0.60018625]), array([-0.56698877, -0.53628012,  0.42252069,  0.46087268]), array([-0.46124371, -0.42353213,  0.53596104,  0.56623364]), array([-0.42956348, -0.43620953,  0.5616718 ,  0.55652605]), array([-0.35281573, -0.418482  ,  0.61279773,  0.56997615]), array([-0.35493505, -0.36745351,  0.61157265,  0.60413402]), array([-0.45870033, -0.40512539,  0.5381394 ,  0.57954587]), array([-0.47827659, -0.42713114,  0.52081811,  0.56352372]), array([-0.5825293 , -0.52572011,  0.40082367,  0.47288304]), array([-0.34031937, -0.35134996,  0.61982476,  0.61363931]), array([-0.446982  , -0.47643146,  0.54791158,  0.52250652]), array([-0.42158133, -0.44232756,  0.56768758,  0.55167593]), array([-0.25886749, -0.39628178,  0.65801795,  0.58562851]), array([-0.45038498, -0.31177587,  0.54511776,  0.63466196]), array([-0.50984639, -0.31308417,  0.48995577,  0.63401759]), array([-0.42846309, -0.53437587,  0.56251167,  0.46307929]), array([-0.34844908, -0.33938593,  0.61529118,  0.62033635]), array([-0.29851273, -0.4876281 ,  0.64100714,  0.51207307]), array([-0.41182835, -0.38943426,  0.57480206,  0.59020417]), array([-0.49584006, -0.40157603,  0.50412561,  0.5820109 ]), array([-0.51775594, -0.51563957,  0.48158985,  0.48385518]), array([-0.35636129, -0.37914258,  0.61074269,  0.59686758]), array([-0.37893843, -0.44815916,  0.59699721,  0.54694915]), array([-0.39831116, -0.37936966,  0.58425013,  0.59672327]), array([-0.39118324, -0.48424675,  0.58904641,  0.51527185]), array([-0.28937336, -0.37309364,  0.64518452,  0.60066724]), array([-0.38375889, -0.42954958,  0.59391002,  0.56168244]), array([-0.46566458, -0.39669026,  0.53212452,  0.58535189]), array([-0.35086615, -0.40206733,  0.61391607,  0.58167161]), array([-0.40629755, -0.45163325,  0.57872472,  0.54408401]), array([-0.40947104, -0.55277303,  0.57648371,  0.44095575]), array([-0.56916938, -0.44987844,  0.41957862,  0.54553587]), array([-0.52779515, -0.35135965,  0.47056591,  0.61363376]), array([-0.36029897, -0.41088917,  0.60842802,  0.5754738 ]), array([-0.41409601, -0.44894017,  0.57317056,  0.54630827]), array([-0.37760869, -0.34575402,  0.59783917,  0.61680966]), array([-0.53726087, -0.39697897,  0.459729  ,  0.58515613]), array([-0.44037091, -0.40675818,  0.55323906,  0.57840106]), array([-0.59124379, -0.31506606,  0.38785408,  0.63303505]), array([-0.53729015, -0.21110203,  0.45969478,  0.67485994]), array([-0.22522809, -0.43240522,  0.67027778,  0.55948702]), array([-0.41006985, -0.40592599,  0.57605791,  0.5789854 ]), array([-0.46100574, -0.3622588 ,  0.53616575,  0.60726317]), array([-0.51454761, -0.44358041,  0.48501625,  0.55066907]), array([-0.4509272 , -0.35180672,  0.54466931,  0.61337756]), array([-0.40563169, -0.50158185,  0.57919162,  0.49841313]), array([-0.31620538, -0.27878402,  0.63246672,  0.64983034]), array([-0.29575514, -0.48222232,  0.64228412,  0.51716693]), array([-0.35576811, -0.19477895,  0.61108842,  0.67975081]), array([-0.35299593, -0.38267224,  0.61269395,  0.59461076]), array([-0.34357564, -0.46253535,  0.61802571,  0.53484675]), array([-0.34651838, -0.5407788 ,  0.61638058,  0.45558566]), array([-0.41972799, -0.39862952,  0.56905924,  0.58403296]), array([-0.48740833, -0.39289748,  0.51228227,  0.58790439]), array([-0.46582594, -0.44640408,  0.53198327,  0.54838253]), array([-0.2571818 , -0.45607788,  0.65867862,  0.54036373]), array([-0.49601178, -0.42345467,  0.50395666,  0.56629157]), array([-0.46119199, -0.4000629 ,  0.53600555,  0.58305203]), array([-0.41208913, -0.30427427,  0.57461513,  0.63829239]), array([-0.44870618, -0.31114374,  0.54650047,  0.63497211]), array([-0.33373945, -0.36196671,  0.62339231,  0.60743732]), array([-0.47095241, -0.25855136,  0.52745031,  0.65814223]), array([-0.47361116, -0.45136512,  0.52506425,  0.54430647]), array([-0.30535048, -0.38707589,  0.63777824,  0.59175355]), array([-0.48088416, -0.42648398,  0.51841145,  0.56401367]), array([-0.33937099, -0.24721153,  0.62034452,  0.66248506]), array([-0.41309044, -0.45314707,  0.57389571,  0.54282385]), array([-0.45632231, -0.26687446,  0.54015734,  0.65481144]), array([-0.42694782, -0.45089706,  0.56366263,  0.54469427]), array([-0.50776566, -0.4722048 ,  0.49211181,  0.52632939]), array([-0.40493783, -0.3522529 ,  0.57967694,  0.61312143]), array([-0.47576495, -0.41596571,  0.52311348,  0.57181511]), array([-0.3498886 , -0.49552391,  0.61447373,  0.50443637]), array([-0.58851161, -0.41182062,  0.39198735,  0.5748076 ]), array([-0.31064668, -0.42030044,  0.63521543,  0.56863656]), array([-0.29170752, -0.43925125,  0.64413254,  0.55412845]), array([-0.54004562, -0.53547167,  0.45645452,  0.46181174]), array([-0.38319134, -0.28337717,  0.59427637,  0.64784055]), array([-0.42006191, -0.45870836,  0.56881279,  0.53813255]), array([-0.40359673, -0.38842282,  0.58061147,  0.5908703 ]), array([-0.34413585, -0.2769687 ,  0.61771394,  0.65060613]), array([-0.4165699 , -0.5577607 ,  0.57137512,  0.43462973]), array([-0.44092852, -0.46835449,  0.55279475,  0.5297585 ]), array([-0.37558426, -0.56206093,  0.59911307,  0.42905421]), array([-0.3696486 , -0.56742584,  0.60279343,  0.42193354]), array([-0.31399798, -0.50425829,  0.63356552,  0.49570513]), array([-0.30546797, -0.48252344,  0.63772198,  0.51688599]), array([-0.39681852, -0.49050127,  0.58526495,  0.50932161]), array([-0.36539476, -0.45209899,  0.60538142,  0.54369707]), array([-0.15934208, -0.47206877,  0.68891952,  0.5264514 ]), array([-0.40673073, -0.35386004,  0.57842036,  0.61219529]), array([-0.49606463, -0.40190992,  0.50390464,  0.58178039]), array([-0.30376986, -0.56835824,  0.63853259,  0.42067673]), array([-0.37504118, -0.3900396 ,  0.59945318,  0.5898043 ]), array([-0.47519618, -0.47546018,  0.5236302 ,  0.5233905 ]), array([-0.48863002, -0.35505686,  0.51111712,  0.61150195]), array([-0.27837127, -0.37009471,  0.65000726,  0.60251963]), array([-0.34601559, -0.33807501,  0.61666297,  0.62105176]), array([-0.35188372, -0.54902744,  0.61333339,  0.44561067]), array([-0.49461884, -0.44556891,  0.50532386,  0.54906133]), array([-0.42827836, -0.38642162,  0.56265233,  0.592181  ]), array([-0.45447002, -0.44502615,  0.54171671,  0.54950134]), array([-0.48924029, -0.34626642,  0.51053299,  0.61652215]), array([-0.56329156, -0.32326643,  0.42743727,  0.62888697]), array([-0.38714464, -0.42065767,  0.59170857,  0.56837235]), array([-0.38720657, -0.42433025,  0.59166804,  0.56563578]), array([-0.35151498, -0.2996559 ,  0.6135448 ,  0.64047353]), array([-0.47312338, -0.37317524,  0.52550382,  0.60061655]), array([-0.33015971, -0.42028082,  0.62529558,  0.56865106]), array([-0.1478299 , -0.46814439,  0.69148125,  0.52994417]), array([-0.33207471, -0.2205356 ,  0.6242807 ,  0.67183633]), array([-0.35110895, -0.5403035 ,  0.61377725,  0.45614924]), array([-0.48293979, -0.37263739,  0.51649701,  0.6009504 ]), array([-0.32537198, -0.38393896,  0.62780018,  0.59379363]), array([-0.26206442, -0.46848225,  0.65675128,  0.52964552]), array([-0.45297027, -0.47399153,  0.54297139,  0.52472091]), array([-0.25014126, -0.44963736,  0.66138442,  0.54573459]), array([-0.41343798, -0.34666671,  0.57364539,  0.61629716]), array([-0.2939693 , -0.49759066,  0.64310345,  0.50239779]), array([-0.4013331 , -0.58835237,  0.58217845,  0.39222632]), array([-0.42435911, -0.46619619,  0.56561413,  0.53165883]), array([-0.38177248, -0.3938278 ,  0.59518886,  0.58728159]), array([-0.4506452 , -0.13548762,  0.54490265,  0.69400512]), array([-0.21526411, -0.57624249,  0.67354388,  0.40981043]), array([-0.4983273 , -0.58737523,  0.50166712,  0.39368812]), array([-0.56329162, -0.49256658,  0.42743719,  0.50732452]), array([-0.43411661, -0.49816187,  0.55816016,  0.5018314 ]), array([-0.382192  , -0.42958089,  0.59491955,  0.56165849]), array([-0.40331677, -0.51063501,  0.58080598,  0.48913382]), array([-0.44041585, -0.3217001 ,  0.55320329,  0.62968964]), array([-0.35666008, -0.38237443,  0.61056825,  0.59480232]), array([-0.33934975, -0.27403971,  0.62035614,  0.65184525]), array([-0.30456937, -0.49215058,  0.63815163,  0.50772809]), array([-0.28751236, -0.28624752,  0.64601598,  0.64657742]), array([-0.47537993, -0.40115874,  0.52346339,  0.58229861]), array([-0.38007452, -0.38800396,  0.59627457,  0.59114544]), array([-0.32961702, -0.50910546,  0.62558182,  0.49072562]), array([-0.38030368, -0.42405934,  0.59612843,  0.56583891]), array([-0.24929285, -0.56883063,  0.66170467,  0.42003775]), array([-0.03475906,  0.09458186,  0.70625194,  0.70075265]), array([-0.20447112,  0.10812245,  0.67689849,  0.69879148]), array([-0.08432885, -0.01351387,  0.70206029,  0.70697763]), array([-0.04926088, -0.03704493,  0.7053888 ,  0.70613573]), array([ 0.01146423, -0.04557441,  0.70701384,  0.70563657]), array([-0.01599785, -0.16012798,  0.70692579,  0.68873727]), array([-0.105137  ,  0.01680998,  0.69924689,  0.70690694]), array([-0.16443125,  0.02278341,  0.68772259,  0.70673964]), array([-0.10828272, -0.24379248,  0.69876667,  0.66375088]), array([-0.44983877,  0.04483661,  0.54556859,  0.70568384]), array([-0.21214536,  0.01787206,  0.67453269,  0.70688089]), array([-0.59466209,  0.1964037 ,  0.38259247,  0.67928314]), array([-0.49500478,  0.05336006,  0.5049458 ,  0.70509056]), array([-0.52725918,  0.17118858,  0.47116638,  0.68607177]), array([-0.51953739,  0.0768062 ,  0.47966749,  0.70292305]), array([-0.47068401, -0.07093691,  0.52768984,  0.70353959]), array([-0.48452677,  0.18322403,  0.51500855,  0.68295604]), array([-0.53563329, -0.15710576,  0.46162428,  0.68943294]), array([-0.53355045,  0.10687316,  0.46403009,  0.69898364]), array([-0.57120679,  0.11277641,  0.41680067,  0.6980555 ])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\AppData\\Local\\Temp/ipykernel_10012/873627341.py:47: DeprecationWarning: The QuantumCircuit.__add__() method is being deprecated.Use the compose() method which is more flexible w.r.t circuit register compatibility.\n",
      "  qc = start_qc + circuit_copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best solution found:                                                                           \n",
      " [0.23427408 0.30394652 0.99415785]\n",
      "\n",
      " Objective function:\n",
      " 0.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.7999999999999999, shape=(), dtype=float64)\n",
      "test\n",
      "[0.23427408 0.30394652 0.99415785]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\slang\\AppData\\Local\\Temp/ipykernel_10012/873627341.py:47: DeprecationWarning: The QuantumCircuit.__add__() method is being deprecated.Use the compose() method which is more flexible w.r.t circuit register compatibility.\n",
      "  qc = start_qc + circuit_copy\n",
      "C:\\Users\\slang\\AppData\\Local\\Temp/ipykernel_10012/873627341.py:190: DeprecationWarning: The QuantumCircuit.__add__() method is being deprecated.Use the compose() method which is more flexible w.r.t circuit register compatibility.\n",
      "  qc = start_qc + circuit_copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  1. -1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1. -1.  1. -1. -1.  1.\n",
      " -1.  1.  1. -1. -1. -1.  1.  1. -1. -1.  1.  1.  1.  1. -1. -1.  1. -1.\n",
      " -1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.  1. -1. -1.  1.  1.  1.\n",
      "  1. -1. -1. -1. -1.  1.  1. -1.  1. -1.  1.  1. -1.  1.  1. -1. -1.  1.\n",
      "  1. -1.  1.  1.  1. -1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1. -1.  1.\n",
      "  1.  1.  1. -1.  1.  1.  1.  1. -1. -1. -1.  1. -1. -1.  1. -1.  1.  1.\n",
      "  1.  1. -1.  1. -1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1.  1.  1.\n",
      " -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1.  1. -1.  1. -1.  1. -1.\n",
      "  1. -1.  1.  1.  1. -1.  1. -1.  1. -1.  1. -1.  1. -1. -1.  1.  1. -1.\n",
      "  1.  1. -1.  1.  1. -1. -1. -1.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1.\n",
      " -1.  1. -1.  1.  1. -1.  1.  1.  1. -1.  1.  1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1. -1. -1.  1. -1. -1.]\n",
      "Accuracy: 0.5476190476190477\n",
      "Precision 1: 0.9611650485436893\n",
      "Precision -1: 0.14953271028037382\n",
      "Recall 1: 0.6605263157894736\n",
      "F1 1: 0.46386821101287246\n",
      "F1 1: 0.675767918088737\n",
      "F1 -1: 0.2519685039370078\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataset_list:\n",
    "    encoded_X, num_qubits = data_encoding(X, \"FRQI\")\n",
    "    vqocc = VQOCC(num_qubits=num_qubits,num_trash_qubits=1,layers=1)\n",
    "    vqocc.train(encoded_X, lr=0.1, n_epochs=100, batch_size=10, verbose_loss=True)\n",
    "    vqocc.test(encoded_X, y)\n",
    "    break\n",
    "# loss_history = vqocc.train(encoded_X, lr=0.1, n_epochs=1, batch_size=10, verbose_loss=True)\n",
    "\n",
    "# qc_vqc = vqocc.circuit\n",
    "# # print(qc)\n",
    "# # print(len(vqocc.parameters))\n",
    "# # print(\"HERE\")\n",
    "# # print(qc.num_parameters)\n",
    "# # print(vqocc.num_parameters)\n",
    "# # parameters_numbers = vqocc.parameters\n",
    "# # param_dic = {}\n",
    "# # for i in range(qc.num_parameters):\n",
    "# #     temp_param = Parameter('{}'.format(i))\n",
    "# #     param_dic[temp_param] = parameters_numbers[i]\n",
    "# # print(qc.parameters)\n",
    "# # print(param_dic)\n",
    "# # batch_size = 5\n",
    "# # batch_index = np.random.randint(0, len(encoded_X), (batch_size,))\n",
    "# # X_batch = [encoded_X[i] for i in batch_index]\n",
    "# # print(X_batch)\n",
    "# # print(qc.qubits)\n",
    "# start_qc = QuantumCircuit(2)\n",
    "# start_qc.initialize(encoded_X[0], start_qc.qubits[0])\n",
    "# start_qc.initialize(encoded_X[1], start_qc.qubits[1])\n",
    "\n",
    "# # qc.initialize('01', qc.qubits)\n",
    "\n",
    "# # qc.initialize(encoded_X[0])\n",
    "# # print(start_qc)\n",
    "# qc = start_qc + qc_vqc\n",
    "# # qc.save_statevector('test1')\n",
    "# # qc.measure_all()\n",
    "# qc.save_statevector('test1')\n",
    "# print(qc)\n",
    "# # Combine such that VQC is on the right side\n",
    "\n",
    "# qc.assign_parameters(vqocc.parameters, inplace=True)\n",
    "# sim = Aer.get_backend('aer_simulator')\n",
    "# qobj = assemble(qc)\n",
    "# job = sim.run(qobj,shots=1024)\n",
    "# result = job.result()\n",
    "# # print(result_sim)\n",
    "# # counts = result_sim.get_statevector(qc)\n",
    "# # print(counts)\n",
    "\n",
    "# data = result.data()\n",
    "# print(data)\n",
    "\n",
    "# print(qc)\n",
    "# print(qc.clbits[0])\n",
    "# print(qc.clbits[0].register)\n",
    "# print(qc.clbits[0].register.bits)\n",
    "\n",
    "# result.get_counts('test1')\n",
    "# from sklearn.datasets import load_digits\n",
    "# print(np.shape(X))\n",
    "# print(np.shape(load_digits().data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c8496",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5430ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
